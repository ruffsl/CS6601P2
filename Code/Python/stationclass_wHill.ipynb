{
 "metadata": {
  "name": "stationClass_wHill"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#from SolarDefs import *",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "data_dir = \"/home/rox/Code/CS6601P2/Data/\"",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#from SolarDirectories import data_dir # = '/media/Data/Project Data/Solar Energy/' \n# Set to your data directory assumes all data is in there - no nesting\nN = 5 # Amount of CV folds\ncv_test_size = 0.2 # Test split size in cv\nfiles_to_use = 'all' # Choices for files_to_use: the string all, or a list of strings corresponding to the unique part of a GEFS filename\nsubmit_name = 'submission_mod_whours.csv'\nargs = { 'N': N, 'cv_test_size': cv_test_size,'files_to_use': files_to_use, 'submit_name': submit_name}",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import csv\nimport os\nimport math\nimport netCDF4 as nc\nimport numpy as np\nimport pandas as pd\nimport Pysolar as ps\nimport datetime\nfrom matplotlib import pyplot as plt\nfrom sklearn import metrics\nfrom sklearn import ensemble\nfrom sklearn.linear_model import Ridge\nfrom sklearn.decomposition import PCA\nfrom sklearn.cross_validation import train_test_split\nfrom itertools import izip\n\n# <codecell>\n\nSEED = 42 # Random seed to keep consistent\n\n# <codecell>\n\n'''\nLoads a list of GEFS files merging them into model format.\n'''\ndef load_GEFS_data(directory,files_to_use,file_sub_str):\n    for i,f in enumerate(files_to_use):\n        if i == 0:\n            T, X, infos = load_GEFS_file(directory,files_to_use[i],file_sub_str)\n            X = np.expand_dims(X, axis=1)\n        else:\n            T, X_new, infos = load_GEFS_file(directory,files_to_use[i],file_sub_str)\n            X_new = np.expand_dims(X_new, axis=1)\n            X = np.hstack((X,X_new))\n    X = X.reshape(X.shape[0],X.shape[1],X.shape[2],X.shape[3],X.shape[4]*X.shape[5])\n    X = np.swapaxes(X,1,4)\n    return T, X, infos\n\n'''\nLoads GEFS file using specified merge technique.\n'''\ndef load_GEFS_file(directory,data_type,file_sub_str):\n    print 'loading',data_type\n    path = os.path.join(directory,data_type+file_sub_str)\n    print 'this is the path: ', path\n    data = nc.Dataset(path,'r+')\n    T = data.variables['intTime'][:]\n    X = data.variables.values()[-1][:,:,:,:,:] # get rid of some GEFS points\n    infos = []\n    lats = data.variables['lat'][:]\n    lons = data.variables['lon'][:]-360\n    for lat in lats:\n        for lon in lons:\n            info = {'lat':lat,'lon':lon}\n            infos.append(info)\n    #X = X.reshape(X.shape[0],55,4,10)                               # Reshape to merge sub_models and time_forcasts\n    #X = np.mean(X,axis=1)                                            # Average models, but not hours\n    #X = X.reshape(X.shape[0],np.prod(X.shape[1:]))                   # Reshape into (n_examples,n_features)\n    return T, X, infos\n\n'''\nLoad csv test/train data splitting out times.\n'''\ndef load_csv_data(path):\n        data = np.loadtxt(path,delimiter=',',dtype=float,skiprows=1)\n        Y = data[:,1:]\n        return Y\n\n'''\nSaves out to a csv.\nJust reads in the example csv and writes out \nover the zeros with the model predictions.\n'''\ndef save_submission(preds,submit_name,data_dir):\n        fexample = open(os.path.join(data_dir,'sampleSubmission.csv'))\n        fout     = open(os.path.join(data_dir,submit_name),'wb')\n        fReader = csv.reader(fexample,delimiter=',', skipinitialspace=True)\n        fwriter = csv.writer(fout)\n        for i,row in enumerate(fReader):\n                if i == 0:\n                        fwriter.writerow(row)\n                else:\n                        row[1:] = preds[i-1]\n                        fwriter.writerow(row)\n        fexample.close()\n        fout.close()\n\n'''\nGet the average mean absolute error for models trained on cv splits\n'''\ndef cv_loop(X, y, model, N):\n    MAEs = 0\n    for i in range(N):\n        X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=.20, random_state = i*SEED)\n        model.fit(X_train, y_train)\n        preds = model.predict(X_cv)\n        mae = metrics.mean_absolute_error(y_cv,preds)\n        print \"MAE (fold %d/%d): %f\" % (i + 1, N, mae)\n        MAEs += mae\n    return MAEs/N\n\n'''\nGet the files to use\n'''\ndef files_To_Use(files_to_use):\n    if files_to_use == 'all':\n            files_to_use = ['dswrf_sfc','dlwrf_sfc','uswrf_sfc','ulwrf_sfc','ulwrf_tatm','pwat_eatm','tcdc_eatm','apcp_sfc','pres_msl','spfh_2m','tcolc_eatm','tmax_2m','tmin_2m','tmp_2m','tmp_sfc']\n    return files_to_use\n\n# <codecell>\n\n'''\nLoad training and testing data\n'''\ndef load_Training_Data(data_dir='./data/',files_to_use='all'):\n    files_to_use = files_To_Use(files_to_use)\n    train_sub_str = '_latlon_subset_19940101_20071231.nc'\n\n    print 'Loading training data...'\n    trainT, trainX, infos = load_GEFS_data(data_dir+'train/',files_to_use,train_sub_str)\n    trainY = load_csv_data(os.path.join(data_dir,'train.csv'))\n    print 'Training data shape',trainX.shape,trainY.shape\n    \n    # Load expected solar values for given days\n    solarData = np.loadtxt(\"../../Data/TSiteSolars.csv\",delimiter=',',dtype=float,skiprows=1)\n    augmentX = solarData[:,1:]\n    \n    return trainT, trainX, trainY, infos, augmentX\n\n'''\nLoad testing data\n'''\ndef load_Testing_Data(data_dir='./data/',files_to_use='all'):\n    files_to_use = files_To_Use(files_to_use)\n    test_sub_str = '_latlon_subset_20080101_20121130.nc'\n\n    print 'Loading test data...'\n    testT, testX, infos = load_GEFS_data(data_dir+'test/',files_to_use,test_sub_str)\n    print 'Test data shape',testX.shape\n   \n    # Load expected solar values for given days\n    solarData = np.loadtxt(\"../../Data/TSiteSolarsTest.csv\",delimiter=',',dtype=float,skiprows=1)\n    augmentX = solarData[:,1:]\n    \n    return testT, testX, infos, augmentX\n\n'''\nLoad station info\n'''\ndef load_Station_Info(data_dir='./data/'):\n\n    print 'Loading station info...'\n    infos = []\n    df = pd.read_csv(os.path.join(data_dir,'station_info.csv')).T\n    for i, station in df.iteritems():\n        temp = {'stid': station['stid'],\n                'lat': station['nlat'],\n                'lon': station['elon'],\n                'elev': station['elev'],\n                'index':i}\n        infos.append(temp)\n    return infos\n\n'''\nGet Times from data\n'''\ndef load_Times(data_dir='./data/',file_to_use='dswrf_sfc',set='Train'):\n    if(set=='Train'):\n        sub_str = '_latlon_subset_20080101_20121130.nc'\n    elif(set=='Test'):\n        sub_str = '_latlon_subset_19940101_20071231.nc'\n\n    print 'Loading test data...'\n    data = load_GEFS_Object(data_dir+'test/',file_to_use,sub_str)\n    return data.variables['intTime'][:]\n\n'''\nFit the Model with training data\n'''\ndef fit_Model(trainX, trainY, model, N):\n    \n    print 'Finding best regularization value for alpha...'\n    alphas = np.logspace(-3,1,8,base=10) # List of alphas to check\n    #alphas = np.array(( 0.1, 0.2, 0.3, 0.4, 0.5, 0.6 ))\n    maes = []\n    for alpha in alphas:\n            model.alpha = alpha\n            mae = cv_loop(trainX,trainY,model,N)\n            maes.append(mae)\n            print 'alpha %.4f mae %.4f' % (alpha,mae)\n    best_alpha = alphas[np.argmin(maes)]\n    print 'Best alpha of %s with mean average error of %s' % (best_alpha,np.min(maes))\n    \n    print 'Fitting model with best alpha...'\n    model.alpha = best_alpha\n    model.fit(trainX,trainY)\n    \n    return times, trainX, trainY\n\n'''\nTest the Model with testing data\n'''\ndef test_Model(testX, model):\n    \n    print 'Predicting...'\n    preds = model.predict(testX)\n    \n    return preds\n\ndef pcaStuff(inputX,inputY):\n    pca = PCA(copy=True, n_components=50, whiten=False)\n    pca.fit(inputX,inputY)\n    outputX = pca.transform(inputX)\n    return pca, outputX\n\ndef getSolarRadiation(lat, lon, time):\n    altitude = ps.GetAltitude(lat, lon, time)\n    return ps.radiation.GetRadiationDirect(time, altitude)\n\ndef getDailySolar(lat, lon, day):\n    dailySolar = 0\n    for minute in range(0, 24*60, 5):\n        time = day + datetime.timedelta(minutes=minute)\n        dailySolar += getSolarRadiation(lat, lon, time)\n    dailySolar *= 300 #3600(joules per watt)*(5.0/60.0)(sample time)\n    return dailySolar\n\ndef getMaxSolar(lat, lon, times):\n    maxSolarEnergy = []\n    for day in times:\n        day = datetime.datetime.strptime(str(day),'%Y%m%d')\n        maxSolarEnergy.append(getDailySolar(lat, lon, day))\n    return maxSolarEnergy\n\ndef genSiteSolar(data_dir='./data/', saveFileName='SiteSolars.csv'):\n    with open(os.path.join(data_dir,saveFileName), 'wb') as csvfile:\n        spamwriter = csv.writer(csvfile)    \n        times,trainY = load_csv_data(os.path.join(data_dir,'test.csv'))\n        df = pd.read_csv(os.path.join(data_dir,'station_info.csv')).T\n        dates = ['Date'] + list(times)\n        spamwriter.writerow(dates)\n        for i, station in df.iteritems():\n            maxSolar = getMaxSolar(station['nlat'], station['elon'], times)\n            stid = [station['stid']] + maxSolar\n            spamwriter.writerow(stid)\n            print('Job: ', i, ' Station: ', station['stid'])\n    \n    a = izip(*csv.reader(open(os.path.join(data_dir,saveFileName), \"rb\")))\n    csv.writer(open(os.path.join(data_dir,'T'+saveFileName), \"wb\")).writerows(a)\n",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named Pysolar",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-2-e82302761297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mPysolar\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mImportError\u001b[0m: No module named Pysolar"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "trainT, trainX, trainY, GEFS_infos, augmentX =load_Training_Data(data_dir,files_to_use)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Loading training data...\nloading dswrf_sfc\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/dswrf_sfc_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " dlwrf_sfc\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/dlwrf_sfc_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " uswrf_sfc\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/uswrf_sfc_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " ulwrf_sfc\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/ulwrf_sfc_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " ulwrf_tatm\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/ulwrf_tatm_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " pwat_eatm\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/pwat_eatm_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " tcdc_eatm\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/tcdc_eatm_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " apcp_sfc\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/apcp_sfc_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " pres_msl\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/pres_msl_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " spfh_2m\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/spfh_2m_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " tcolc_eatm\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/tcolc_eatm_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " tmax_2m\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/tmax_2m_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " tmin_2m\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/tmin_2m_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " tmp_2m\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/tmp_2m_latlon_subset_19940101_20071231.nc\nloading"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " tmp_sfc\nthis is the path:  /home/rox/Code/CS6601P2/Data/train/tmp_sfc_latlon_subset_19940101_20071231.nc\nTraining data shape"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " (5113, 144, 11, 5, 15) (5113, 98)\n"
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def dayOfYear(T):\n    '''Get the day of year time vector'''\n    days = []\n    for t in T:\n        day = datetime.datetime.strptime(str(t),'%Y%m%d%H')\n        day = day.timetuple().tm_yday\n        days.append(day)\n    days = np.array(days)\n    return days\n\ndef compexDayOfYear(T):\n    '''Get the compex day of year time vector'''\n    T = dayOfYear(T)\n    real = np.sin((T/365.0)*2*np.pi)\n    imaginary = np.cos((T/365.0)*2*np.pi)\n    compexDays = np.vstack((real,imaginary)).T\n    return compexDays\n\ndef monthOfYear(T):\n    '''Get the day of year time vector'''\n    months = []\n    for t in T:\n        month = datetime.datetime.strptime(str(t),'%Y%m%d%H')\n        month = month.timetuple().tm_mon\n        months.append(month)\n    months = np.array(months)\n    return months\n\ndef compexMonthOfYear(T):\n    '''Get the compex day of year time vector'''\n    T = monthOfYear(T)\n    real = np.sin((T/12.0)*2*np.pi)\n    imaginary = np.cos((T/12.0)*2*np.pi)\n    compexMonths = np.vstack((real,imaginary)).T\n    return compexMonths",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "lol = compexMonthOfYear(trainT)\nplt.plot(lol.T)\nplt.show()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "trainDays = dayOfYear(trainT)\ntrainDays = np.expand_dims(trainDays,1)\ntrainCompDays = compexDayOfYear(trainT)\ntrainMonths = monthOfYear(trainT)\ntrainMonths = np.expand_dims(trainMonths,1)\ntrainCompMonths = compexMonthOfYear(trainT)\nprint 'trainDays', trainDays.shape\nprint 'trainCompDays', trainCompDays.shape\nprint 'trainMonths', trainMonths.shape\nprint 'trainCompMonths', trainCompMonths.shape\nmod_train = np.hstack((trainDays,trainCompDays,trainMonths,trainCompMonths))\nmod_train.shape",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "trainDays (5113, 1)\ntrainCompDays (5113, 2)\ntrainMonths (5113, 1)\ntrainCompMonths (5113, 2)\n"
      },
      {
       "output_type": "pyout",
       "prompt_number": 160,
       "text": "(5113, 6)"
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "trainCompMonths.shape",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 144,
       "text": "(5113, 2)"
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "station_infos = load_Station_Info(data_dir)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Loading station info...\n"
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "class station:\n\n    def __init__(self, info, model, config):\n        '''Create a Station Model'''\n        # Store the info about the station\n        self.info   = info\n        \n        # Store the regression model used\n        # for each weather prediction model\n        self.models = [model]*11\n        \n        # Store the configuration of the station\n        self.config = config\n        \n        # Store the GEFS points to be used\n        self.GEFSs  = self.getGEFSs()\n    \n    def fit(self, X_train, y_train, mod_train=None):\n        '''Fit the Station Model'''\n        X_train = self.filterGEFSX(X_train)\n        y_train = self.filterGEFSy(y_train)\n        for i,model in enumerate(self.models):\n            print \"Fitting Model:\", i\n            X = X_train[:,:,i]\n            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n            if mod_train != None:\n                X = np.hstack((X,mod_train))\n            model.fit(X,y_train)\n         \n    def predict(self, X_test, wModels=None, mod_train=None):\n        '''Predict with the Station Model'''\n        X_test = self.filterGEFSX(X_test)\n        if (wModels == None):\n            wModels = range(11)\n        for i,index in enumerate(wModels):\n            print \"Predicting Model:\", index\n            X = X_test[:,:,index]\n            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n            if mod_train != None:\n                X = np.hstack((X,mod_train))\n            model = self.models[index]\n            if i == 0:\n                prediction = model.predict(X)\n            else:\n                prediction = np.vstack((prediction,model.predict(X)))\n        return prediction\n    \n    def getDistance(self,station, GEFS):\n        '''Find the distance from the Station'''\n        lat1, lon1 = [station['lat'], station['lon']]\n        lat2, lon2 = [GEFS['lat'], GEFS['lon']]\n        radius = 6371 # km\n    \n        dlat = math.radians(lat2-lat1)\n        dlon = math.radians(lon2-lon1)\n        a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n            * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n        d = radius * c\n    \n        return d\n    \n    def getGEFSs(self):\n        '''Get only the GEFS that are the N closest for config'''\n        distances = []\n        for index, GEFS in enumerate(self.info['GEFSs']):\n            distance = self.getDistance(self.info['station'], GEFS)\n            distances.append([index,distance])\n        distances = sorted(distances,key=lambda l:l[1])\n        GEFSs = []\n        N = self.config['nGEFS']\n        for index, GEFS in distances[0:N]:\n            GEFSs.append(index)\n        return GEFSs\n    \n    def filterGEFSX(self, X):\n        '''Filter X data to just used GEFS points'''\n        for i, GEFS in enumerate(self.GEFSs):\n            if i == 0:\n                X_new = X[:,GEFS]\n                X_new = np.expand_dims(X_new, axis=1)\n            else:\n                X_temp = X[:,GEFS]\n                X_temp = np.expand_dims(X_temp, axis=1)\n                X_new = np.hstack((X_new,X_temp))\n        return X_new\n    \n    def filterGEFSy(self, y):\n        '''Filter y data to just used GEFS points'''\n        y_new = y[:,self.info['station']['index']]\n        return y_new\n            \n        ",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 133
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n          'learning_rate': 0.01, 'loss': 'ls'}\nmodel = ensemble.GradientBoostingRegressor()\nconfig = {'nGEFS':4}\n\nstations = []\nfor station_info in station_infos:\n    info = {'station':station_info,\n            'GEFSs':GEFS_infos}\n    temp_station = station(info, model, config)\n    stations.append(temp_station)\n\n    '''\nfor station in stations:\n    station.fit(X_train, y_train)\n    \nfor station in stations:\n    prediction = station.predict(X_test)'''",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 134
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "lol = stations[0]",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "lol.fit(trainX,trainY,trainMonths)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Fitting Model: 0\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 1\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 2\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 3\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 4\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 5\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 6\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 7\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 8\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 9\nFitting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 10\n"
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "lul = lol.predict(trainX,wModels=None, mod_train=trainMonths)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Predicting Model: 0\nPredicting Model: 1\nPredicting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 2\nPredicting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 3\nPredicting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 4\nPredicting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 5\nPredicting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 6\nPredicting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 7\nPredicting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 8\nPredicting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 9\nPredicting Model:"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": " 10\n"
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "lul.shape",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 168,
       "text": "(11, 5113)"
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "for model in range(11):\n    print metrics.mean_absolute_error(trainY[:,0],lul[model])",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "1973393.60755\n2021839.43911\n2050525.51532\n2032369.56764\n2035938.08363\n2056586.83572\n2050929.41594\n2045861.22706\n2056738.81833\n2069794.06649\n1847157.65004\n"
      }
     ],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "plt.plot(lul[0])\nplt.plot(trainY[:,0])\nplt.show()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 142
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Optimization for weather forecast"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def move_operator(weights):\n    \nweight_list = []\nfor i in range(len(weights)):\n    for j in range(i+1,len(weights)):\n        temp1 = list(weights)\n        temp1[i] += 0.01\n        temp1[j] -= 0.01\n        weight_list.append(temp1)\n        temp2 = list(weights)\n        temp2[i] -= 0.01\n        temp2[j] += 0.01\n        weight_list.append(temp2)\n    \n    return weight_list",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def score(truth, prediction, weights):\n    \n    for i in enumerate(weights):\n        prediction[:,i] *= weights[i]\n        \n    final_prediction = np.sum(prediction,axis=1) \n    \n    return metrics.mean_absolute_error(truth,final_prediction)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#from __future__ import division\n\ndef random_init():\n    weights = list(np.random.randint(10, size=11))\n    sum = np.sum(weights)\n    weights = [temp/(sum*1.0) for temp in weights]\n    return weights",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def hillclimb(weights, truth, prediction, max_evaluations):\n\n    best = random_init()\n    best_score = score(truth, predition, best)\n    \n    num_evaluations=1\n    \n    while num_evaluations < max_evaluations:\n        # examine moves around our current position\n        move_made=False\n        for next in move_operator(best):\n            if num_evaluations >= max_evaluations:\n                break\n            \n            # see if this move is better than the current\n            next_score = score(truth, predition, next)\n            num_evaluations+=1\n            if next_score > best_score:\n                best=next\n                best_score=next_score\n                move_made=True\n                break # depth first search\n            \n        if not move_made:\n            break # we couldn't find a better move \n                     # (must be at a local maximum)\n    \n    return (num_evaluations,best_score,best)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def hillclimb_reset(weights, truth, prediction, max_evaluations):\n\n    best = weights\n    best_score = score(truth, predition, best)\n    \n    num_evaluations=0\n    \n    while num_evaluations < max_evaluations:\n        remaining_evaluations=max_evaluations-num_evaluations\n        \n        evaluated,score,found=hillclimb(weights, truth, prediction, max_evaluations)\n        \n        num_evaluations+=evaluated\n        if score > best_score or best is None:\n            best_score=score\n            best=found\n    \n    return (num_evaluations,best_score,best)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "weights = [1]*4\nweight_list = []\nfor i in range(len(weights)):\n    for j in range(i+1,len(weights)):\n        temp1 = list(weights)\n        temp1[i] += 0.1\n        temp1[j] -= 0.1\n        weight_list.append(temp1)\n        temp2 = list(weights)\n        temp2[i] -= 0.1\n        temp2[j] += 0.1\n        weight_list.append(temp2)\nweight_list",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 61,
       "text": "[[1.1, 0.9, 1, 1],\n [0.9, 1.1, 1, 1],\n [1.1, 1, 0.9, 1],\n [0.9, 1, 1.1, 1],\n [1.1, 1, 1, 0.9],\n [0.9, 1, 1, 1.1],\n [1, 1.1, 0.9, 1],\n [1, 0.9, 1.1, 1],\n [1, 1.1, 1, 0.9],\n [1, 0.9, 1, 1.1],\n [1, 1, 1.1, 0.9],\n [1, 1, 0.9, 1.1]]"
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
