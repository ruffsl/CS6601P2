{
 "metadata": {
  "name": "StationClass"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from SolarDefs import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "cannot import name genfromtext",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-23-b2b3278405fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from SolarDefs import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgenfromtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mImportError\u001b[0m: cannot import name genfromtext"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir = \"/home/rox/Code/CS6601P2/Data/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from SolarDirectories import data_dir # = '/media/Data/Project Data/Solar Energy/' \n",
      "# Set to your data directory assumes all data is in there - no nesting\n",
      "N = 5 # Amount of CV folds\n",
      "cv_test_size = 0.2 # Test split size in cv\n",
      "files_to_use = ['dswrf_sfc','dswrf_sfc'] # Choices for files_to_use: the string all, or a list of strings corresponding to the unique part of a GEFS filename\n",
      "submit_name = 'submission_mod_whours.csv'\n",
      "args = { 'N': N, 'cv_test_size': cv_test_size,'files_to_use': files_to_use, 'submit_name': submit_name}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import os\n",
      "import netCDF4 as nc\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import Pysolar as ps\n",
      "import datetime\n",
      "from matplotlib import pyplot as plt\n",
      "from sklearn import metrics\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from itertools import izip\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "SEED = 42 # Random seed to keep consistent\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "'''\n",
      "Load csv test/train data splitting out times.\n",
      "'''\n",
      "def load_csv_data(path):\n",
      "        data = np.loadtxt(path,delimiter=',',dtype=float,skiprows=1)\n",
      "        Y = data[:,1:]\n",
      "        return Y\n",
      "\n",
      "'''\n",
      "Saves out to a csv.\n",
      "Just reads in the example csv and writes out \n",
      "over the zeros with the model predictions.\n",
      "'''\n",
      "def save_submission(preds,submit_name,data_dir):\n",
      "        fexample = open(os.path.join(data_dir,'sampleSubmission.csv'))\n",
      "        fout     = open(os.path.join(data_dir,submit_name),'wb')\n",
      "        fReader = csv.reader(fexample,delimiter=',', skipinitialspace=True)\n",
      "        fwriter = csv.writer(fout)\n",
      "        for i,row in enumerate(fReader):\n",
      "                if i == 0:\n",
      "                        fwriter.writerow(row)\n",
      "                else:\n",
      "                        row[1:] = preds[i-1]\n",
      "                        fwriter.writerow(row)\n",
      "        fexample.close()\n",
      "        fout.close()\n",
      "\n",
      "'''\n",
      "Get the average mean absolute error for models trained on cv splits\n",
      "'''\n",
      "def cv_loop(X, y, model, N):\n",
      "    MAEs = 0\n",
      "    for i in range(N):\n",
      "        X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=.20, random_state = i*SEED)\n",
      "        model.fit(X_train, y_train)\n",
      "        preds = model.predict(X_cv)\n",
      "        mae = metrics.mean_absolute_error(y_cv,preds)\n",
      "        print \"MAE (fold %d/%d): %f\" % (i + 1, N, mae)\n",
      "        MAEs += mae\n",
      "    return MAEs/N\n",
      "\n",
      "'''\n",
      "Get the files to use\n",
      "'''\n",
      "def files_To_Use(files_to_use):\n",
      "    if files_to_use == 'all':\n",
      "            files_to_use = ['dswrf_sfc','dlwrf_sfc','uswrf_sfc','ulwrf_sfc','ulwrf_tatm','pwat_eatm','tcdc_eatm','apcp_sfc','pres_msl','spfh_2m','tcolc_eatm','tmax_2m','tmin_2m','tmp_2m','tmp_sfc']\n",
      "    return files_to_use\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "'''\n",
      "Load training and testing data\n",
      "'''\n",
      "def load_Training_Data(data_dir='./data/',files_to_use='all'):\n",
      "    files_to_use = files_To_Use(files_to_use)\n",
      "    train_sub_str = '_latlon_subset_19940101_20071231.nc'\n",
      "\n",
      "    print 'Loading training data...'\n",
      "    trainT, trainX, infos = load_GEFS_data(data_dir+'train/',files_to_use,train_sub_str)\n",
      "    trainY = load_csv_data(os.path.join(data_dir,'train.csv'))\n",
      "    print 'Training data shape',trainX.shape,trainY.shape\n",
      "    \n",
      "    # Load expected solar values for given days\n",
      "    solarData = np.loadtxt(\"../../Data/TSiteSolars.csv\",delimiter=',',dtype=float,skiprows=1)\n",
      "    augmentX = solarData[:,1:]\n",
      "    \n",
      "    return trainT, trainX, trainY, infos, augmentX\n",
      "\n",
      "'''\n",
      "Load testing data\n",
      "'''\n",
      "def load_Testing_Data(data_dir='./data/',files_to_use='all'):\n",
      "    files_to_use = files_To_Use(files_to_use)\n",
      "    test_sub_str = '_latlon_subset_20080101_20121130.nc'\n",
      "\n",
      "    print 'Loading test data...'\n",
      "    testT, testX, infos = load_GEFS_data(data_dir+'test/',files_to_use,test_sub_str)\n",
      "    print 'Test data shape',testX.shape\n",
      "   \n",
      "    # Load expected solar values for given days\n",
      "    solarData = np.loadtxt(\"../../Data/TSiteSolarsTest.csv\",delimiter=',',dtype=float,skiprows=1)\n",
      "    augmentX = solarData[:,1:]\n",
      "    \n",
      "    return testT, testX, infos, augmentX\n",
      "\n",
      "'''\n",
      "Load station info\n",
      "'''\n",
      "def load_Station_Info(data_dir='./data/'):\n",
      "\n",
      "    print 'Loading station info...'\n",
      "    infos = []\n",
      "    df = pd.read_csv(os.path.join(data_dir,'station_info.csv')).T\n",
      "    for i, station in df.iteritems():\n",
      "        temp = {'stid': station['stid'],\n",
      "                'lat': station['nlat'],\n",
      "                'lon': station['elon'],\n",
      "                'elev': station['elev']}\n",
      "        infos.append(temp)\n",
      "    return infos\n",
      "\n",
      "'''\n",
      "Get Times from data\n",
      "'''\n",
      "def load_Times(data_dir='./data/',file_to_use='dswrf_sfc',set='Train'):\n",
      "    if(set=='Train'):\n",
      "        sub_str = '_latlon_subset_20080101_20121130.nc'\n",
      "    elif(set=='Test'):\n",
      "        sub_str = '_latlon_subset_19940101_20071231.nc'\n",
      "\n",
      "    print 'Loading test data...'\n",
      "    data = load_GEFS_Object(data_dir+'test/',file_to_use,sub_str)\n",
      "    return data.variables['intTime'][:]\n",
      "\n",
      "'''\n",
      "Fit the Model with training data\n",
      "'''\n",
      "def fit_Model(trainX, trainY, model, N):\n",
      "    \n",
      "    print 'Finding best regularization value for alpha...'\n",
      "    alphas = np.logspace(-3,1,8,base=10) # List of alphas to check\n",
      "    #alphas = np.array(( 0.1, 0.2, 0.3, 0.4, 0.5, 0.6 ))\n",
      "    maes = []\n",
      "    for alpha in alphas:\n",
      "            model.alpha = alpha\n",
      "            mae = cv_loop(trainX,trainY,model,N)\n",
      "            maes.append(mae)\n",
      "            print 'alpha %.4f mae %.4f' % (alpha,mae)\n",
      "    best_alpha = alphas[np.argmin(maes)]\n",
      "    print 'Best alpha of %s with mean average error of %s' % (best_alpha,np.min(maes))\n",
      "    \n",
      "    print 'Fitting model with best alpha...'\n",
      "    model.alpha = best_alpha\n",
      "    model.fit(trainX,trainY)\n",
      "    \n",
      "    return times, trainX, trainY\n",
      "\n",
      "'''\n",
      "Test the Model with testing data\n",
      "'''\n",
      "def test_Model(testX, model):\n",
      "    \n",
      "    print 'Predicting...'\n",
      "    preds = model.predict(testX)\n",
      "    \n",
      "    return preds\n",
      "\n",
      "def pcaStuff(inputX,inputY):\n",
      "    pca = PCA(copy=True, n_components=50, whiten=False)\n",
      "    pca.fit(inputX,inputY)\n",
      "    outputX = pca.transform(inputX)\n",
      "    return pca, outputX\n",
      "\n",
      "def getSolarRadiation(lat, lon, time):\n",
      "    altitude = ps.GetAltitude(lat, lon, time)\n",
      "    return ps.radiation.GetRadiationDirect(time, altitude)\n",
      "\n",
      "def getDailySolar(lat, lon, day):\n",
      "    dailySolar = 0\n",
      "    for minute in range(0, 24*60, 5):\n",
      "        time = day + datetime.timedelta(minutes=minute)\n",
      "        dailySolar += getSolarRadiation(lat, lon, time)\n",
      "    dailySolar *= 300 #3600(joules per watt)*(5.0/60.0)(sample time)\n",
      "    return dailySolar\n",
      "\n",
      "def getMaxSolar(lat, lon, times):\n",
      "    maxSolarEnergy = []\n",
      "    for day in times:\n",
      "        day = datetime.datetime.strptime(str(day),'%Y%m%d')\n",
      "        maxSolarEnergy.append(getDailySolar(lat, lon, day))\n",
      "    return maxSolarEnergy\n",
      "\n",
      "def genSiteSolar(data_dir='./data/', saveFileName='SiteSolars.csv'):\n",
      "    with open(os.path.join(data_dir,saveFileName), 'wb') as csvfile:\n",
      "        spamwriter = csv.writer(csvfile)    \n",
      "        times,trainY = load_csv_data(os.path.join(data_dir,'test.csv'))\n",
      "        df = pd.read_csv(os.path.join(data_dir,'station_info.csv')).T\n",
      "        dates = ['Date'] + list(times)\n",
      "        spamwriter.writerow(dates)\n",
      "        for i, station in df.iteritems():\n",
      "            maxSolar = getMaxSolar(station['nlat'], station['elon'], times)\n",
      "            stid = [station['stid']] + maxSolar\n",
      "            spamwriter.writerow(stid)\n",
      "            print('Job: ', i, ' Station: ', station['stid'])\n",
      "    \n",
      "    a = izip(*csv.reader(open(os.path.join(data_dir,saveFileName), \"rb\")))\n",
      "    csv.writer(open(os.path.join(data_dir,'T'+saveFileName), \"wb\")).writerows(a)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Loads a list of GEFS files merging them into model format.\n",
      "'''\n",
      "def load_GEFS_data(directory,files_to_use,file_sub_str):\n",
      "    for i,f in enumerate(files_to_use):\n",
      "        if i == 0:\n",
      "            T, X, infos = load_GEFS_file(directory,files_to_use[i],file_sub_str)\n",
      "            X = np.expand_dims(X, axis=1)\n",
      "        else:\n",
      "            T, X_new, infos = load_GEFS_file(directory,files_to_use[i],file_sub_str)\n",
      "            X_new = np.expand_dims(X_new, axis=1)\n",
      "            X = np.hstack((X,X_new))\n",
      "    X = X.reshape(X.shape[0],X.shape[1],X.shape[2],X.shape[3],X.shape[4]*X.shape[5])\n",
      "    X = np.swapaxes(X,1,4)\n",
      "    return T, X, infos\n",
      "\n",
      "'''\n",
      "Loads GEFS file using specified merge technique.\n",
      "'''\n",
      "def load_GEFS_file(directory,data_type,file_sub_str):\n",
      "    print 'loading',data_type\n",
      "    path = os.path.join(directory,data_type+file_sub_str)\n",
      "    print 'this is the path: ', path\n",
      "    data = nc.Dataset(path,'r+')\n",
      "    T = data.variables['intTime'][:]\n",
      "    X = data.variables.values()[-1][:,:,:,:,:] # get rid of some GEFS points\n",
      "    infos = []\n",
      "    lats = data.variables['lat'][:]\n",
      "    lons = data.variables['lon'][:]-360\n",
      "    for lat in lats:\n",
      "        for lon in lons:\n",
      "            info = {'lat':lat,'lon':lon}\n",
      "            infos.append(info)\n",
      "    #X = X.reshape(X.shape[0],55,4,10)                               # Reshape to merge sub_models and time_forcasts\n",
      "    #X = np.mean(X,axis=1)                                            # Average models, but not hours\n",
      "    #X = X.reshape(X.shape[0],np.prod(X.shape[1:]))                   # Reshape into (n_examples,n_features)\n",
      "    return T, X, infos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainX_PCAtrainT, trainX, trainY, infos, augmentX = load_Training_Data(data_dir,files_to_use)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data...\n",
        "loading dswrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/dswrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dswrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/dswrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "Training data shape"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (5113, 144, 11, 5, 2) (5113, 98)\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "load_Station_Info(data_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading station info...\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "[{'elev': 397, 'lat': 34.80833, 'lon': -98.02325, 'stid': 'ACME'},\n",
        " {'elev': 295, 'lat': 34.79851, 'lon': -96.66909, 'stid': 'ADAX'},\n",
        " {'elev': 416, 'lat': 34.58722, 'lon': -99.33808, 'stid': 'ALTU'},\n",
        " {'elev': 440, 'lat': 34.91418, 'lon': -98.29216, 'stid': 'APAC'},\n",
        " {'elev': 719, 'lat': 36.07204, 'lon': -99.90308, 'stid': 'ARNE'},\n",
        " {'elev': 758, 'lat': 36.80253, 'lon': -100.53012, 'stid': 'BEAV'},\n",
        " {'elev': 511, 'lat': 35.40185, 'lon': -99.05847, 'stid': 'BESS'},\n",
        " {'elev': 184, 'lat': 35.96305, 'lon': -95.86621, 'stid': 'BIXB'},\n",
        " {'elev': 304, 'lat': 36.75443, 'lon': -97.25452, 'stid': 'BLAC'},\n",
        " {'elev': 1267, 'lat': 36.69256, 'lon': -102.49713, 'stid': 'BOIS'},\n",
        " {'elev': 281, 'lat': 35.17156, 'lon': -96.63121, 'stid': 'BOWL'},\n",
        " {'elev': 352, 'lat': 36.412009999999995, 'lon': -97.69394, 'stid': 'BREC'},\n",
        " {'elev': 239, 'lat': 35.7805, 'lon': -96.35404, 'stid': 'BRIS'},\n",
        " {'elev': 559, 'lat': 36.83129, 'lon': -99.64101, 'stid': 'BUFF'},\n",
        " {'elev': 301, 'lat': 36.63459, 'lon': -96.81045999999999, 'stid': 'BURB'},\n",
        " {'elev': 228, 'lat': 33.89376, 'lon': -97.26918, 'stid': 'BURN'},\n",
        " {'elev': 520, 'lat': 35.5915, 'lon': -99.27059, 'stid': 'BUTL'},\n",
        " {'elev': 345, 'lat': 34.8497, 'lon': -97.0033, 'stid': 'BYAR'},\n",
        " {'elev': 589, 'lat': 36.028659999999995, 'lon': -99.34652, 'stid': 'CAMA'},\n",
        " {'elev': 208, 'lat': 34.608959999999996, 'lon': -96.33309, 'stid': 'CENT'},\n",
        " {'elev': 291, 'lat': 35.65282, 'lon': -96.80407, 'stid': 'CHAN'},\n",
        " {'elev': 362, 'lat': 36.748129999999996, 'lon': -98.36274, 'stid': 'CHER'},\n",
        " {'elev': 694, 'lat': 35.54615, 'lon': -99.7279, 'stid': 'CHEY'},\n",
        " {'elev': 328, 'lat': 35.03236, 'lon': -97.91445999999999, 'stid': 'CHIC'},\n",
        " {'elev': 186, 'lat': 34.65657, 'lon': -95.32596, 'stid': 'CLAY'},\n",
        " {'elev': 221, 'lat': 34.223209999999995, 'lon': -95.2487, 'stid': 'CLOU'},\n",
        " {'elev': 299,\n",
        "  'lat': 35.680009999999996,\n",
        "  'lon': -94.84895999999999,\n",
        "  'stid': 'COOK'},\n",
        " {'elev': 250, 'lat': 36.90987, 'lon': -95.88553, 'stid': 'COPA'},\n",
        " {'elev': 197, 'lat': 33.92075, 'lon': -96.32027, 'stid': 'DURA'},\n",
        " {'elev': 419, 'lat': 35.54848, 'lon': -98.03654, 'stid': 'ELRE'},\n",
        " {'elev': 603, 'lat': 35.20494, 'lon': -99.80344000000001, 'stid': 'ERIC'},\n",
        " {'elev': 200, 'lat': 35.30324, 'lon': -95.65706999999999, 'stid': 'EUFA'},\n",
        " {'elev': 405, 'lat': 36.263529999999996, 'lon': -98.49766, 'stid': 'FAIR'},\n",
        " {'elev': 330, 'lat': 36.84053, 'lon': -96.42777, 'stid': 'FORA'},\n",
        " {'elev': 530, 'lat': 36.72562, 'lon': -99.14234, 'stid': 'FREE'},\n",
        " {'elev': 422, 'lat': 35.14887, 'lon': -98.46607, 'stid': 'FTCB'},\n",
        " {'elev': 997, 'lat': 36.60183, 'lon': -101.6013, 'stid': 'GOOD'},\n",
        " {'elev': 330, 'lat': 35.84891, 'lon': -97.47978, 'stid': 'GUTH'},\n",
        " {'elev': 183, 'lat': 35.74798, 'lon': -95.64047, 'stid': 'HASK'},\n",
        " {'elev': 493, 'lat': 35.484390000000005, 'lon': -98.48151, 'stid': 'HINT'},\n",
        " {'elev': 478, 'lat': 34.989709999999995, 'lon': -99.05283, 'stid': 'HOBA'},\n",
        " {'elev': 497, 'lat': 34.6855, 'lon': -99.83331, 'stid': 'HOLL'},\n",
        " {'elev': 912, 'lat': 36.85518, 'lon': -101.22547, 'stid': 'HOOK'},\n",
        " {'elev': 175, 'lat': 34.030840000000005, 'lon': -95.54011, 'stid': 'HUGO'},\n",
        " {'elev': 110, 'lat': 33.83013, 'lon': -94.8803, 'stid': 'IDAB'},\n",
        " {'elev': 304, 'lat': 36.4821, 'lon': -94.78286999999999, 'stid': 'JAYX'},\n",
        " {'elev': 1322, 'lat': 36.829370000000004, 'lon': -102.8782, 'stid': 'KENT'},\n",
        " {'elev': 341, 'lat': 34.52887, 'lon': -97.76484, 'stid': 'KETC'},\n",
        " {'elev': 396, 'lat': 36.38435, 'lon': -98.11139, 'stid': 'LAHO'},\n",
        " {'elev': 181, 'lat': 34.30876, 'lon': -95.99716, 'stid': 'LANE'},\n",
        " {'elev': 232, 'lat': 34.035790000000006, 'lon': -96.94394, 'stid': 'MADI'},\n",
        " {'elev': 460, 'lat': 34.83592, 'lon': -99.42398, 'stid': 'MANG'},\n",
        " {'elev': 327, 'lat': 36.06434, 'lon': -97.21271, 'stid': 'MARE'},\n",
        " {'elev': 555, 'lat': 36.98707, 'lon': -99.01109, 'stid': 'MAYR'},\n",
        " {'elev': 230, 'lat': 34.88231, 'lon': -95.78096, 'stid': 'MCAL'},\n",
        " {'elev': 332, 'lat': 36.79242, 'lon': -97.74577, 'stid': 'MEDF'},\n",
        " {'elev': 487, 'lat': 34.729209999999995, 'lon': -98.56936, 'stid': 'MEDI'},\n",
        " {'elev': 247, 'lat': 36.88832, 'lon': -94.84437, 'stid': 'MIAM'},\n",
        " {'elev': 430, 'lat': 35.27225, 'lon': -97.95553000000001, 'stid': 'MINC'},\n",
        " {'elev': 284, 'lat': 34.31072, 'lon': -94.82275, 'stid': 'MTHE'},\n",
        " {'elev': 366, 'lat': 36.8981, 'lon': -96.91035, 'stid': 'NEWK'},\n",
        " {'elev': 356, 'lat': 34.96774, 'lon': -97.95201999999999, 'stid': 'NINN'},\n",
        " {'elev': 206, 'lat': 36.74374, 'lon': -95.60795, 'stid': 'NOWA'},\n",
        " {'elev': 255, 'lat': 36.031259999999996, 'lon': -96.49749, 'stid': 'OILT'},\n",
        " {'elev': 263, 'lat': 35.43172, 'lon': -96.26265, 'stid': 'OKEM'},\n",
        " {'elev': 205, 'lat': 35.58211, 'lon': -95.91473, 'stid': 'OKMU'},\n",
        " {'elev': 291, 'lat': 34.7155, 'lon': -97.22924, 'stid': 'PAUL'},\n",
        " {'elev': 283, 'lat': 36.36114, 'lon': -96.76986, 'stid': 'PAWN'},\n",
        " {'elev': 292, 'lat': 35.99865, 'lon': -97.04831, 'stid': 'PERK'},\n",
        " {'elev': 201, 'lat': 36.36914, 'lon': -95.27138000000001, 'stid': 'PRYO'},\n",
        " {'elev': 589, 'lat': 35.89904, 'lon': -98.96038, 'stid': 'PUTN'},\n",
        " {'elev': 293, 'lat': 36.3559, 'lon': -97.15306, 'stid': 'REDR'},\n",
        " {'elev': 538, 'lat': 35.12275, 'lon': -99.36001, 'stid': 'RETR'},\n",
        " {'elev': 283, 'lat': 34.19365, 'lon': -97.58811999999999, 'stid': 'RING'},\n",
        " {'elev': 157, 'lat': 35.43815, 'lon': -94.79805, 'stid': 'SALL'},\n",
        " {'elev': 545, 'lat': 36.190329999999996, 'lon': -99.0403, 'stid': 'SEIL'},\n",
        " {'elev': 328, 'lat': 35.36492, 'lon': -96.94821999999999, 'stid': 'SHAW'},\n",
        " {'elev': 282, 'lat': 36.4153, 'lon': -96.03706, 'stid': 'SKIA'},\n",
        " {'elev': 774, 'lat': 36.59749, 'lon': -100.26191999999999, 'stid': 'SLAP'},\n",
        " {'elev': 373, 'lat': 35.54208, 'lon': -97.34146, 'stid': 'SPEN'},\n",
        " {'elev': 173, 'lat': 35.26527, 'lon': -95.18115999999999, 'stid': 'STIG'},\n",
        " {'elev': 272, 'lat': 36.12093, 'lon': -97.09527, 'stid': 'STIL'},\n",
        " {'elev': 256, 'lat': 34.87642, 'lon': -96.06981999999999, 'stid': 'STUA'},\n",
        " {'elev': 320, 'lat': 34.5661, 'lon': -96.95048, 'stid': 'SULP'},\n",
        " {'elev': 290, 'lat': 35.97235, 'lon': -94.98671, 'stid': 'TAHL'},\n",
        " {'elev': 204, 'lat': 34.7107, 'lon': -95.01151999999999, 'stid': 'TALI'},\n",
        " {'elev': 387, 'lat': 34.43972, 'lon': -99.13755, 'stid': 'TIPT'},\n",
        " {'elev': 268, 'lat': 34.33262, 'lon': -96.67895, 'stid': 'TISH'},\n",
        " {'elev': 236, 'lat': 36.77536, 'lon': -95.22094, 'stid': 'VINI'},\n",
        " {'elev': 345, 'lat': 34.982240000000004, 'lon': -97.52109, 'stid': 'WASH'},\n",
        " {'elev': 517, 'lat': 35.84185, 'lon': -98.52615, 'stid': 'WATO'},\n",
        " {'elev': 283, 'lat': 34.16775, 'lon': -97.98815, 'stid': 'WAUR'},\n",
        " {'elev': 538, 'lat': 35.5083, 'lon': -98.77509, 'stid': 'WEAT'},\n",
        " {'elev': 348, 'lat': 36.011, 'lon': -94.64496, 'stid': 'WEST'},\n",
        " {'elev': 199, 'lat': 34.90092, 'lon': -95.34805, 'stid': 'WILB'},\n",
        " {'elev': 143, 'lat': 34.98426, 'lon': -94.68778, 'stid': 'WIST'},\n",
        " {'elev': 625, 'lat': 36.42329, 'lon': -99.41682, 'stid': 'WOOD'},\n",
        " {'elev': 269, 'lat': 36.51806, 'lon': -96.34222, 'stid': 'WYNO'}]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "info = {'id':123,\n",
      "        'lat':1,\n",
      "        'lon':2,\n",
      "        'elev':3,}\n",
      "\n",
      "param = {'nStations':4,\n",
      "         'forecastModel':11,\n",
      "         "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-7-494a5b6f18ab>, line 8)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-494a5b6f18ab>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class station:\n",
      "\n",
      "    def __init__(self, info, model, param, mesos):\n",
      "        self.info   = info       #info is dictionary with lat, lon, elevation\n",
      "        self.model = model\n",
      "        self.models = [model]*11\n",
      "        self.param = param\n",
      "        self.n = n\n",
      "        self.mesos = mesos\n",
      "    \n",
      "    def fit(self, X, y):\n",
      "        for model in self.models:\n",
      "            model.fit(X,y)           #specify dimension of X to get model\n",
      "         \n",
      "    def predict(self, X_new, wModels=None):\n",
      "        \n",
      "        prediction = []\n",
      "        if wModels = None:\n",
      "            wModels = range(11)\n",
      "        for i,index in enumerate(wModels):\n",
      "            model = self.models[index]\n",
      "            if i == 0:\n",
      "                prediction = model.predict(X_new)\n",
      "            else:\n",
      "                np.hstack((prediction,model.predict(X_new)))\n",
      "        prediction = np.mean(prediction,axis=1)\n",
      "        return prediction\n",
      "    \n",
      "    def filters(self, X, y=None)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "test1 = np.array(5)\n",
      "test2 = np.array(range(10))\n",
      "print np.append([test1],[test2], axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}