{
 "metadata": {
  "name": "StationClass"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from SolarDefs import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir = \"/home/rox/Code/CS6601P2/Data/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from SolarDirectories import data_dir # = '/media/Data/Project Data/Solar Energy/' \n",
      "# Set to your data directory assumes all data is in there - no nesting\n",
      "files_to_use = 'all' # Choices for files_to_use: the string all, or a list of strings corresponding to the unique part of a GEFS filename\n",
      "submit_name = 'submission_mod_whours.csv'\n",
      "args = { 'files_to_use': files_to_use, 'submit_name': submit_name}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainT, trainX, trainY, GEFS_infos, augmentX =load_Training_Data(data_dir,files_to_use)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data...\n",
        "loading dswrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/dswrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dlwrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/dlwrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " uswrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/uswrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ulwrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/ulwrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ulwrf_tatm\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/ulwrf_tatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pwat_eatm\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/pwat_eatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tcdc_eatm\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tcdc_eatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " apcp_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/apcp_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pres_msl\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/pres_msl_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " spfh_2m\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/spfh_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tcolc_eatm\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tcolc_eatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmax_2m\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tmax_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmin_2m\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tmin_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmp_2m\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tmp_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmp_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tmp_sfc_latlon_subset_19940101_20071231.nc\n",
        "Training data shape"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (5113, 144, 11, 5, 15) (5113, 98)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dayOfYear(T):\n",
      "    '''Get the day of year time vector'''\n",
      "    days = []\n",
      "    for t in T:\n",
      "        day = datetime.datetime.strptime(str(t),'%Y%m%d%H')\n",
      "        day = day.timetuple().tm_yday\n",
      "        days.append(day)\n",
      "    days = np.array(days)\n",
      "    return days\n",
      "\n",
      "def compexDayOfYear(T):\n",
      "    '''Get the compex day of year time vector'''\n",
      "    T = dayOfYear(T)\n",
      "    real = np.sin((T/365.0)*2*np.pi)\n",
      "    imaginary = np.cos((T/365.0)*2*np.pi)\n",
      "    compexDays = np.vstack((real,imaginary)).T\n",
      "    return compexDays\n",
      "\n",
      "def monthOfYear(T):\n",
      "    '''Get the day of year time vector'''\n",
      "    months = []\n",
      "    for t in T:\n",
      "        month = datetime.datetime.strptime(str(t),'%Y%m%d%H')\n",
      "        month = month.timetuple().tm_mon\n",
      "        months.append(month)\n",
      "    months = np.array(months)\n",
      "    return months\n",
      "\n",
      "def compexMonthOfYear(T):\n",
      "    '''Get the compex day of year time vector'''\n",
      "    T = monthOfYear(T)\n",
      "    real = np.sin((T/12.0)*2*np.pi)\n",
      "    imaginary = np.cos((T/12.0)*2*np.pi)\n",
      "    compexMonths = np.vstack((real,imaginary)).T\n",
      "    return compexMonths"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainDays = dayOfYear(trainT)\n",
      "trainDays = np.expand_dims(trainDays,1)\n",
      "trainCompDays = compexDayOfYear(trainT)\n",
      "trainMonths = monthOfYear(trainT)\n",
      "trainMonths = np.expand_dims(trainMonths,1)\n",
      "trainCompMonths = compexMonthOfYear(trainT)\n",
      "print 'trainDays', trainDays.shape\n",
      "print 'trainCompDays', trainCompDays.shape\n",
      "print 'trainMonths', trainMonths.shape\n",
      "print 'trainCompMonths', trainCompMonths.shape\n",
      "mod_train = np.hstack((trainDays,trainCompDays,trainMonths,trainCompMonths))\n",
      "mod_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "trainDays (5113, 1)\n",
        "trainCompDays (5113, 2)\n",
        "trainMonths (5113, 1)\n",
        "trainCompMonths (5113, 2)\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(5113, 6)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "station_infos = load_Station_Info(data_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading station info...\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class station:\n",
      "\n",
      "    def __init__(self, info, model, config):\n",
      "        '''Create a Station Model'''\n",
      "        # Store the info about the station\n",
      "        self.info   = info\n",
      "        \n",
      "        # Store the regression model used\n",
      "        # for each weather prediction model\n",
      "        self.models = [model]*11\n",
      "        \n",
      "        # Store the configuration of the station\n",
      "        self.config = config\n",
      "        \n",
      "        # Store the GEFS points to be used\n",
      "        self.GEFSs  = self.getGEFSs()\n",
      "    \n",
      "    def fit(self, X_train, y_train, mod_train=None):\n",
      "        '''Fit the Station Model'''\n",
      "        X_train = self.filterGEFSX(X_train)\n",
      "        y_train = self.filterGEFSy(y_train)\n",
      "        for i,model in enumerate(self.models):\n",
      "            print \"Fitting Model:\", i\n",
      "            X = X_train[:,:,i]\n",
      "            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n",
      "            if mod_train != None:\n",
      "                X = np.hstack((X,mod_train))\n",
      "            model.fit(X,y_train)\n",
      "         \n",
      "    def predict(self, X_test, wModels=None, mod_train=None):\n",
      "        '''Predict with the Station Model'''\n",
      "        X_test = self.filterGEFSX(X_test)\n",
      "        if (wModels == None):\n",
      "            wModels = range(11)\n",
      "        for i,index in enumerate(wModels):\n",
      "            print \"Predicting Model:\", index\n",
      "            X = X_test[:,:,index]\n",
      "            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n",
      "            if mod_train != None:\n",
      "                X = np.hstack((X,mod_train))\n",
      "            model = self.models[index]\n",
      "            if i == 0:\n",
      "                prediction = model.predict(X)\n",
      "            else:\n",
      "                prediction = np.vstack((prediction,model.predict(X)))\n",
      "        return prediction\n",
      "    \n",
      "    def getDistance(self,station, GEFS):\n",
      "        '''Find the distance from the Station'''\n",
      "        lat1, lon1 = [station['lat'], station['lon']]\n",
      "        lat2, lon2 = [GEFS['lat'], GEFS['lon']]\n",
      "        radius = 6371 # km\n",
      "    \n",
      "        dlat = math.radians(lat2-lat1)\n",
      "        dlon = math.radians(lon2-lon1)\n",
      "        a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
      "            * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
      "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
      "        d = radius * c\n",
      "    \n",
      "        return d\n",
      "    \n",
      "    def getGEFSs(self):\n",
      "        '''Get only the GEFS that are the N closest for config'''\n",
      "        distances = []\n",
      "        for index, GEFS in enumerate(self.info['GEFSs']):\n",
      "            distance = self.getDistance(self.info['station'], GEFS)\n",
      "            distances.append([index,distance])\n",
      "        distances = sorted(distances,key=lambda l:l[1])\n",
      "        GEFSs = []\n",
      "        N = self.config['nGEFS']\n",
      "        for index, GEFS in distances[0:N]:\n",
      "            GEFSs.append(index)\n",
      "        return GEFSs\n",
      "    \n",
      "    def filterGEFSX(self, X):\n",
      "        '''Filter X data to just used GEFS points'''\n",
      "        for i, GEFS in enumerate(self.GEFSs):\n",
      "            if i == 0:\n",
      "                X_new = X[:,GEFS]\n",
      "                X_new = np.expand_dims(X_new, axis=1)\n",
      "            else:\n",
      "                X_temp = X[:,GEFS]\n",
      "                X_temp = np.expand_dims(X_temp, axis=1)\n",
      "                X_new = np.hstack((X_new,X_temp))\n",
      "        return X_new\n",
      "    \n",
      "    def filterGEFSy(self, y):\n",
      "        '''Filter y data to just used GEFS points'''\n",
      "        y_new = y[:,self.info['station']['index']]\n",
      "        return y_new\n",
      "            \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n",
      "          'learning_rate': 0.01, 'loss': 'ls'}\n",
      "model = ensemble.GradientBoostingRegressor()\n",
      "config = {'nGEFS':4}\n",
      "\n",
      "stations = []\n",
      "for station_info in station_infos:\n",
      "    info = {'station':station_info,\n",
      "            'GEFSs':GEFS_infos}\n",
      "    temp_station = station(info, model, config)\n",
      "    stations.append(temp_station)\n",
      "\n",
      "    '''\n",
      "for station in stations:\n",
      "    station.fit(X_train, y_train)\n",
      "    \n",
      "for station in stations:\n",
      "    prediction = station.predict(X_test)'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lol = stations[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lol.fit(trainX,trainY,trainMonths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting Model: 0\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lul = lol.predict(trainX,wModels=None, mod_train=trainMonths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicting Model: 0\n",
        "Predicting Model: 1\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lul.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "(11, 5113)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for model in range(11):\n",
      "    print metrics.mean_absolute_error(trainY[:,0],lul[model])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1973393.60755\n",
        "2021839.43911\n",
        "2050525.51532\n",
        "2032369.56764\n",
        "2035938.08363\n",
        "2056586.83572\n",
        "2050929.41594\n",
        "2045861.22706\n",
        "2056738.81833\n",
        "2069794.06649\n",
        "1847157.65004\n"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(lul[0])\n",
      "plt.plot(trainY[:,0])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "temp = np.sum(prediction,axis=0)\n",
      "temp.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 90,
       "text": [
        "(5113,)"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = [1/11.0]*11\n",
      "prediction = np.array(lul)\n",
      "\n",
      "for i,j in enumerate(weights):\n",
      "    prediction[i] *= j\n",
      "    \n",
      "final_prediction = np.sum(prediction,axis=1)\n",
      "print final_prediction.shape\n",
      "\n",
      "blah = metrics.mean_absolute_error(trainY[:,0],final_prediction)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Found array with dim 11. Expected 5113",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-84-7ca9022bb230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mfinal_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mblah\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/usr/lib/pymodules/python2.7/sklearn/metrics/metrics.pyc\u001b[0m in \u001b[0;36mmean_absolute_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/pymodules/python2.7/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_arrays\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             raise ValueError(\"Found array with dim %d. Expected %d\"\n\u001b[0;32m--> 193\u001b[0;31m                              % (size, n_samples))\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_lists\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Found array with dim 11. Expected 5113"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(11,)\n"
       ]
      }
     ],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_evaluations,best_score,best,first_score = hillclimb(trainY[:,0], lul, 11000)\n",
      "\n",
      "\n",
      "#num_evaluations,best_score,best = (1,2,3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print best\n",
      "print first_score\n",
      "print best_score\n",
      "print num_evaluations\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.0052631578947368203, -0.27210526315789485, -0.23947368421052645, -0.0010526315789473641, -0.017368421052631595, 0.036315789473684211, 0.052631578947368411, 0.08157894736842107, 0.1063157894736842, 0.085263157894736846, 1.1626315789473691]\n",
        "1956811.4697\n",
        "1837884.63867\n",
        "4578\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 120,
       "text": [
        "array([ 12091898.94714584,   7079857.63987767,  12014431.91361274, ...,\n",
        "         8577281.80137956,  12662782.99430099,  12811744.92646638])"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def move_operator(weights):\n",
      "    weight_list = []\n",
      "    for i in range(len(weights)):\n",
      "        for j in range(i+1,len(weights)):\n",
      "            temp1 = list(weights)\n",
      "            temp1[i] += 0.01\n",
      "            temp1[j] -= 0.01\n",
      "            weight_list.append(temp1)\n",
      "            temp2 = list(weights)\n",
      "            temp2[i] -= 0.01\n",
      "            temp2[j] += 0.01\n",
      "            weight_list.append(temp2)\n",
      "    return weight_list\n",
      "\n",
      "def score(truth, predicted, weights):\n",
      "    \n",
      "    prediction = np.array(predicted)\n",
      "    for i,j in enumerate(weights):\n",
      "        prediction[i] *= j\n",
      "        \n",
      "    final_prediction = np.sum(prediction,axis=0) \n",
      "    \n",
      "    return metrics.mean_absolute_error(truth,final_prediction)\n",
      "\n",
      "def random_init():\n",
      "    weights = list(np.random.randint(10, size=11))\n",
      "    sum = np.sum(weights)\n",
      "    weights = [temp/(sum*1.0) for temp in weights]\n",
      "    return weights\n",
      "\n",
      "def hillclimb(truth, prediction, max_evaluations):\n",
      "\n",
      "    best = random_init()\n",
      "    best_score = score(truth, prediction, best)\n",
      "    first_score = best_score\n",
      "    \n",
      "    num_evaluations=1\n",
      "    \n",
      "    while num_evaluations < max_evaluations:\n",
      "        # examine moves around our current position\n",
      "        move_made=False\n",
      "        for next in move_operator(best):\n",
      "            if num_evaluations >= max_evaluations:\n",
      "                break\n",
      "            \n",
      "            # see if this move is better than the current\n",
      "            next_score = score(truth, prediction, next)\n",
      "            num_evaluations+=1\n",
      "            if next_score < best_score:\n",
      "                best=next\n",
      "                best_score=next_score\n",
      "                move_made=True\n",
      "                break # depth first search\n",
      "            \n",
      "        if not move_made:\n",
      "            break # we couldn't find a better move \n",
      "                     # (must be at a local maximum)\n",
      "    \n",
      "    return (num_evaluations,best_score,best,first_score)\n",
      "\n",
      "def hillclimb_reset(weights, truth, prediction, max_evaluations):\n",
      "\n",
      "    best = weights\n",
      "    best_score = score(truth, prediction, best)\n",
      "    \n",
      "    num_evaluations=0\n",
      "    \n",
      "    while num_evaluations < max_evaluations:\n",
      "        remaining_evaluations=max_evaluations-num_evaluations\n",
      "        \n",
      "        evaluated,score,found=hillclimb(weights, truth, prediction, max_evaluations)\n",
      "        \n",
      "        num_evaluations+=evaluated\n",
      "        if score > best_score or best is None:\n",
      "            best_score=score\n",
      "            best=found\n",
      "    \n",
      "    return (num_evaluations,best_score,best)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    }
   ],
   "metadata": {}
  }
 ]
}