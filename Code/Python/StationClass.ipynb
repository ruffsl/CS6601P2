{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from SolarDefs import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data_dir = \"/home/rox/Code/CS6601P2/Data/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from SolarDirectories import data_dir # = '/media/Data/Project Data/Solar Energy/' \n",
      "# Set to your data directory assumes all data is in there - no nesting\n",
      "files_to_use = 'all' # Choices for files_to_use: the string all, or a list of strings corresponding to the unique part of a GEFS filename\n",
      "submit_name = 'submission_mod_whours.csv'\n",
      "args = { 'files_to_use': files_to_use, 'submit_name': submit_name}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainT, trainX, trainY, GEFS_infos, augmentX =load_Training_Data(data_dir,files_to_use)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data...\n",
        "loading dswrf_sfc\n",
        "this is the path:  /media/Data/SolarData/train/dswrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dlwrf_sfc\n",
        "this is the path:  /media/Data/SolarData/train/dlwrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " uswrf_sfc\n",
        "this is the path:  /media/Data/SolarData/train/uswrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ulwrf_sfc\n",
        "this is the path:  /media/Data/SolarData/train/ulwrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ulwrf_tatm\n",
        "this is the path:  /media/Data/SolarData/train/ulwrf_tatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pwat_eatm\n",
        "this is the path:  /media/Data/SolarData/train/pwat_eatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tcdc_eatm\n",
        "this is the path:  /media/Data/SolarData/train/tcdc_eatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " apcp_sfc\n",
        "this is the path:  /media/Data/SolarData/train/apcp_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pres_msl\n",
        "this is the path:  /media/Data/SolarData/train/pres_msl_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " spfh_2m\n",
        "this is the path:  /media/Data/SolarData/train/spfh_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tcolc_eatm\n",
        "this is the path:  /media/Data/SolarData/train/tcolc_eatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmax_2m\n",
        "this is the path:  /media/Data/SolarData/train/tmax_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmin_2m\n",
        "this is the path:  /media/Data/SolarData/train/tmin_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmp_2m\n",
        "this is the path:  /media/Data/SolarData/train/tmp_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmp_sfc\n",
        "this is the path:  /media/Data/SolarData/train/tmp_sfc_latlon_subset_19940101_20071231.nc\n",
        "Training data shape"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (5113, 144, 11, 5, 15) (5113, 98)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dayOfYear(T):\n",
      "    '''Get the day of year time vector'''\n",
      "    days = []\n",
      "    for t in T:\n",
      "        day = datetime.datetime.strptime(str(t),'%Y%m%d%H')\n",
      "        day = day.timetuple().tm_yday\n",
      "        days.append(day)\n",
      "    days = np.array(days)\n",
      "    return days\n",
      "\n",
      "def compexDayOfYear(T):\n",
      "    '''Get the compex day of year time vector'''\n",
      "    T = dayOfYear(T)\n",
      "    real = np.sin((T/365.0)*2*np.pi)\n",
      "    imaginary = np.cos((T/365.0)*2*np.pi)\n",
      "    compexDays = np.vstack((real,imaginary)).T\n",
      "    return compexDays\n",
      "\n",
      "def monthOfYear(T):\n",
      "    '''Get the day of year time vector'''\n",
      "    months = []\n",
      "    for t in T:\n",
      "        month = datetime.datetime.strptime(str(t),'%Y%m%d%H')\n",
      "        month = month.timetuple().tm_mon\n",
      "        months.append(month)\n",
      "    months = np.array(months)\n",
      "    return months\n",
      "\n",
      "def compexMonthOfYear(T):\n",
      "    '''Get the compex day of year time vector'''\n",
      "    T = monthOfYear(T)\n",
      "    real = np.sin((T/12.0)*2*np.pi)\n",
      "    imaginary = np.cos((T/12.0)*2*np.pi)\n",
      "    compexMonths = np.vstack((real,imaginary)).T\n",
      "    return compexMonths"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainDays = dayOfYear(trainT)\n",
      "trainDays = np.expand_dims(trainDays,1)\n",
      "trainCompDays = compexDayOfYear(trainT)\n",
      "trainMonths = monthOfYear(trainT)\n",
      "trainMonths = np.expand_dims(trainMonths,1)\n",
      "trainCompMonths = compexMonthOfYear(trainT)\n",
      "print 'trainDays', trainDays.shape\n",
      "print 'trainCompDays', trainCompDays.shape\n",
      "print 'trainMonths', trainMonths.shape\n",
      "print 'trainCompMonths', trainCompMonths.shape\n",
      "mod_train = np.hstack((trainDays,trainCompDays,trainMonths,trainCompMonths))\n",
      "mod_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "trainDays (5113, 1)\n",
        "trainCompDays (5113, 2)\n",
        "trainMonths (5113, 1)\n",
        "trainCompMonths (5113, 2)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(5113, 6)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "station_infos = load_Station_Info(data_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading station info...\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class station:\n",
      "\n",
      "    def __init__(self, info, model, config):\n",
      "        '''Create a Station Model'''\n",
      "        # Store the info about the station\n",
      "        self.info   = info\n",
      "        \n",
      "        # Store the regression model used\n",
      "        # for each weather prediction model\n",
      "        self.models = [model]*11\n",
      "        \n",
      "        # Store the configuration of the station\n",
      "        self.config = config\n",
      "        \n",
      "        # Store the GEFS points to be used\n",
      "        self.GEFSs  = self.getGEFSs()\n",
      "    \n",
      "    def fit(self, X_train, y_train, mod_train=None):\n",
      "        '''Fit the Station Model'''\n",
      "        X_train = self.filterGEFSX(X_train)\n",
      "        y_train = self.filterGEFSy(y_train)\n",
      "        for i,model in enumerate(self.models):\n",
      "            print \"Fitting Model:\", i\n",
      "            X = X_train[:,:,i]\n",
      "            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n",
      "            if mod_train != None:\n",
      "                X = np.hstack((X,mod_train))\n",
      "            model.fit(X,y_train)\n",
      "         \n",
      "    def predict(self, X_test, wModels=None, mod_train=None):\n",
      "        '''Predict with the Station Model'''\n",
      "        X_test = self.filterGEFSX(X_test)\n",
      "        if (wModels == None):\n",
      "            wModels = range(11)\n",
      "        for i,index in enumerate(wModels):\n",
      "            print \"Predicting Model:\", index\n",
      "            X = X_test[:,:,index]\n",
      "            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n",
      "            if mod_train != None:\n",
      "                X = np.hstack((X,mod_train))\n",
      "            model = self.models[index]\n",
      "            if i == 0:\n",
      "                prediction = model.predict(X)\n",
      "            else:\n",
      "                prediction = np.vstack((prediction,model.predict(X)))\n",
      "        return prediction\n",
      "    \n",
      "    def getDistance(self,station, GEFS):\n",
      "        '''Find the distance from the Station'''\n",
      "        lat1, lon1 = [station['lat'], station['lon']]\n",
      "        lat2, lon2 = [GEFS['lat'], GEFS['lon']]\n",
      "        radius = 6371 # km\n",
      "    \n",
      "        dlat = math.radians(lat2-lat1)\n",
      "        dlon = math.radians(lon2-lon1)\n",
      "        a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
      "            * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
      "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
      "        d = radius * c\n",
      "    \n",
      "        return d\n",
      "    \n",
      "    def getGEFSs(self):\n",
      "        '''Get only the GEFS that are the N closest for config'''\n",
      "        distances = []\n",
      "        for index, GEFS in enumerate(self.info['GEFSs']):\n",
      "            distance = self.getDistance(self.info['station'], GEFS)\n",
      "            distances.append([index,distance])\n",
      "        distances = sorted(distances,key=lambda l:l[1])\n",
      "        GEFSs = []\n",
      "        N = self.config['nGEFS']\n",
      "        for index, GEFS in distances[0:N]:\n",
      "            GEFSs.append(index)\n",
      "        return GEFSs\n",
      "    \n",
      "    def filterGEFSX(self, X):\n",
      "        '''Filter X data to just used GEFS points'''\n",
      "        for i, GEFS in enumerate(self.GEFSs):\n",
      "            if i == 0:\n",
      "                X_new = X[:,GEFS]\n",
      "                X_new = np.expand_dims(X_new, axis=1)\n",
      "            else:\n",
      "                X_temp = X[:,GEFS]\n",
      "                X_temp = np.expand_dims(X_temp, axis=1)\n",
      "                X_new = np.hstack((X_new,X_temp))\n",
      "        return X_new\n",
      "    \n",
      "    def filterGEFSy(self, y):\n",
      "        '''Filter y data to just used GEFS points'''\n",
      "        y_new = y[:,self.info['station']['index']]\n",
      "        return y_new\n",
      "            \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n",
      "          'learning_rate': 0.01, 'loss': 'ls'}\n",
      "model = ensemble.GradientBoostingRegressor(params)\n",
      "config = {'nGEFS':4}\n",
      "\n",
      "stations = []\n",
      "for station_info in station_infos:\n",
      "    info = {'station':station_info,\n",
      "            'GEFSs':GEFS_infos}\n",
      "    temp_station = station(info, model, config)\n",
      "    stations.append(temp_station)\n",
      "\n",
      "    '''\n",
      "for station in stations:\n",
      "    station.fit(X_train, y_train)\n",
      "    \n",
      "for station in stations:\n",
      "    prediction = station.predict(X_test)'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'ensemble' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-f54b52a34050>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n\u001b[0;32m      2\u001b[0m           'learning_rate': 0.01, 'loss': 'ls'}\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'nGEFS'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'ensemble' is not defined"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lol = stations[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lol.fit(trainX,trainY,trainMonths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting Model: 0\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lul = lol.predict(trainX,wModels=None, mod_train=trainMonths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicting Model: 0\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lul.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "(11, 5113)"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for model in range(11):\n",
      "    print metrics.mean_absolute_error(trainY[:,0],lul[model])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(lul[0])\n",
      "plt.plot(trainY[:,0])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainY.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(5113, 98)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_evaluations,best_score,best,first_score = hillclimb(trainY[:,0], lul, 11000)\n",
      "\n",
      "\n",
      "#num_evaluations,best_score,best = (1,2,3)\n",
      "print best\n",
      "print first_score\n",
      "print best_score\n",
      "print num_evaluations\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def move_operator(weights):\n",
      "    weight_list = []\n",
      "    for i in range(len(weights)):\n",
      "        for j in range(i+1,len(weights)):\n",
      "            temp1 = weights\n",
      "            temp1[i] += 0.01\n",
      "            temp1[j] -= 0.01\n",
      "            weight_list.append(temp1)\n",
      "            temp2 = weights\n",
      "            temp2[i] -= 0.01\n",
      "            temp2[j] += 0.01\n",
      "            weight_list.append(temp2)\n",
      "    return weight_list\n",
      "\n",
      "def score(truth, predicted, weights):\n",
      "    \n",
      "    prediction = np.array(predicted)\n",
      "    for i,j in enumerate(weights):\n",
      "        prediction[i] *= j\n",
      "        \n",
      "    final_prediction = np.sum(prediction,axis=0)\n",
      "    return metrics.mean_absolute_error(truth,final_prediction)\n",
      "\n",
      "def random_init():\n",
      "    weights = np.random.randint(10, size=11)\n",
      "    sum = np.sum(weights)\n",
      "    weights = [temp/(sum*1.0) for temp in weights]\n",
      "    return weights\n",
      "\n",
      "def hillclimb(truth, prediction, max_evaluations):\n",
      "\n",
      "    best = random_init()\n",
      "    best_score = score(truth, prediction, best)\n",
      "    first_score = best_score\n",
      "    \n",
      "    num_evaluations=1\n",
      "    \n",
      "    while num_evaluations < max_evaluations:\n",
      "        # examine moves around our current position\n",
      "        move_made=False\n",
      "        for next in move_operator(best):\n",
      "            if num_evaluations >= max_evaluations:\n",
      "                break\n",
      "            \n",
      "            # see if this move is better than the current\n",
      "            next_score = score(truth, prediction, next)\n",
      "            num_evaluations+=1\n",
      "            if next_score < best_score:\n",
      "                best=next\n",
      "                best_score=next_score\n",
      "                move_made=True\n",
      "                break # depth first search\n",
      "            \n",
      "        if not move_made:\n",
      "            break # we couldn't find a better move \n",
      "                     # (must be at a local maximum)\n",
      "    \n",
      "    return (num_evaluations,best_score,best,first_score)\n",
      "\n",
      "def hillclimb_reset(weights, truth, prediction, max_evaluations):\n",
      "\n",
      "    best = weights\n",
      "    best_score = score(truth, prediction, best)\n",
      "    \n",
      "    num_evaluations=0\n",
      "    \n",
      "    while num_evaluations < max_evaluations:\n",
      "        remaining_evaluations=max_evaluations-num_evaluations\n",
      "        \n",
      "        evaluated,score,found=hillclimb(weights, truth, prediction, max_evaluations)\n",
      "        \n",
      "        num_evaluations+=evaluated\n",
      "        if score > best_score or best is None:\n",
      "            best_score=score\n",
      "            best=found\n",
      "    \n",
      "    return (num_evaluations,best_score,best)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getWeights(station, X, y, mod_train=None):\n",
      "    predictions = station.predict(X,wModels=None, mod_train=trainMonths)\n",
      "    stationTruth = station.filterGEFSy(y)\n",
      "    monthIndexs = []\n",
      "    for month in range(1,13):\n",
      "        monthIndexs.append(np.argwhere(trainMonths==month)[:,0])\n",
      "    monthWeights = []\n",
      "    for month in monthIndexs:\n",
      "        monthPredictions = predictions[:,month]\n",
      "        monthTruth = stationTruth[month]\n",
      "        num_evaluations,best_score,best,first_score = hillclimb(monthTruth, monthPredictions, 11000)\n",
      "        monthWeights.append(best)\n",
      "    return monthWeights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "monthWeights = getWeights(lol, trainX, trainY, mod_train=trainMonths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicting Model: 0\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(monthWeights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "12"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Function to wrap station training for annealer\n",
      "def trainStation(x):\n",
      "    STATION_NUM = 5\n",
      "    \n",
      "    # Assign our annealing parameters to the param dictionary\n",
      "    params = {'n_estimators': x[0], 'max_depth': x[1], 'min_samples_split': x[2],\n",
      "              'learning_rate': x[3], 'loss': 'ls'}\n",
      "    \n",
      "    # Create GBR model with annealing params\n",
      "    model = ensemble.GradientBoostingRegressor(params)\n",
      "    config = {'nGEFS':4}\n",
      "    \n",
      "    # Grab the station info (lat,lon,alt,etc)\n",
      "    info = {'station':station_infos[STATION_NUM],\n",
      "            'GEFSs':GEFS_infos}\n",
      "    \n",
      "    # Create a station\n",
      "    temp_station = station(info, model, config)\n",
      "    \n",
      "    # Train the station\n",
      "    temp_station.fit(trainX, trainY, mod_train=mod_train)\n",
      "    \n",
      "    # Make a prediction with this station model (for all t)\n",
      "    stationPrediction = temp_station.predict(trainX, wModels=None, mod_train=mod_train)\n",
      "    stationTruth = temp_station.filterGEFSy(trainY)\n",
      "    \n",
      "    # Return the MAE of the prediction\n",
      "    return metrics.mean_absolute_error(stationTruth, stationPrediction[10])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.array([500, 4, 1, 0.01])\n",
      "result = trainStation(x)\n",
      "print result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "unhashable type: 'dict'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-a1a8aca71a4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainStation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-15-9eb62fdf6080>\u001b[0m in \u001b[0;36mtrainStation\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Train the station\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mtemp_station\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Make a prediction with this station model (for all t)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-10-8f4d1e6e89fc>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, mod_train)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmod_train\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmod_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwModels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1124\u001b[0m         \"\"\"\n\u001b[0;32m   1125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1126\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \"\"\"\n\u001b[1;32m--> 550\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;31m# Check input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"learning_rate must be greater than 0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLOSS_FUNCTIONS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss '{0:s}' not supported. \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'dict'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting Model: 0\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print trainX.shape, trainY.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5113, 144, 11, 5, 15) (5113, 98)\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}