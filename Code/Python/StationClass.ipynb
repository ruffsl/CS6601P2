{
 "metadata": {
  "name": "StationClass"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from SolarDefs import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir = \"/home/rox/Code/CS6601P2/Data/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from SolarDirectories import data_dir # = '/media/Data/Project Data/Solar Energy/' \n",
      "# Set to your data directory assumes all data is in there - no nesting\n",
      "N = 5 # Amount of CV folds\n",
      "cv_test_size = 0.2 # Test split size in cv\n",
      "files_to_use = 'all' # Choices for files_to_use: the string all, or a list of strings corresponding to the unique part of a GEFS filename\n",
      "submit_name = 'submission_mod_whours.csv'\n",
      "args = { 'N': N, 'cv_test_size': cv_test_size,'files_to_use': files_to_use, 'submit_name': submit_name}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 93
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import os\n",
      "import math\n",
      "import netCDF4 as nc\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import Pysolar as ps\n",
      "import datetime\n",
      "from matplotlib import pyplot as plt\n",
      "from sklearn import metrics\n",
      "from sklearn import ensemble\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from itertools import izip\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "SEED = 42 # Random seed to keep consistent\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "'''\n",
      "Load csv test/train data splitting out times.\n",
      "'''\n",
      "def load_csv_data(path):\n",
      "        data = np.loadtxt(path,delimiter=',',dtype=float,skiprows=1)\n",
      "        Y = data[:,1:]\n",
      "        return Y\n",
      "\n",
      "'''\n",
      "Saves out to a csv.\n",
      "Just reads in the example csv and writes out \n",
      "over the zeros with the model predictions.\n",
      "'''\n",
      "def save_submission(preds,submit_name,data_dir):\n",
      "        fexample = open(os.path.join(data_dir,'sampleSubmission.csv'))\n",
      "        fout     = open(os.path.join(data_dir,submit_name),'wb')\n",
      "        fReader = csv.reader(fexample,delimiter=',', skipinitialspace=True)\n",
      "        fwriter = csv.writer(fout)\n",
      "        for i,row in enumerate(fReader):\n",
      "                if i == 0:\n",
      "                        fwriter.writerow(row)\n",
      "                else:\n",
      "                        row[1:] = preds[i-1]\n",
      "                        fwriter.writerow(row)\n",
      "        fexample.close()\n",
      "        fout.close()\n",
      "\n",
      "'''\n",
      "Get the average mean absolute error for models trained on cv splits\n",
      "'''\n",
      "def cv_loop(X, y, model, N):\n",
      "    MAEs = 0\n",
      "    for i in range(N):\n",
      "        X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=.20, random_state = i*SEED)\n",
      "        model.fit(X_train, y_train)\n",
      "        preds = model.predict(X_cv)\n",
      "        mae = metrics.mean_absolute_error(y_cv,preds)\n",
      "        print \"MAE (fold %d/%d): %f\" % (i + 1, N, mae)\n",
      "        MAEs += mae\n",
      "    return MAEs/N\n",
      "\n",
      "'''\n",
      "Get the files to use\n",
      "'''\n",
      "def files_To_Use(files_to_use):\n",
      "    if files_to_use == 'all':\n",
      "            files_to_use = ['dswrf_sfc','dlwrf_sfc','uswrf_sfc','ulwrf_sfc','ulwrf_tatm','pwat_eatm','tcdc_eatm','apcp_sfc','pres_msl','spfh_2m','tcolc_eatm','tmax_2m','tmin_2m','tmp_2m','tmp_sfc']\n",
      "    return files_to_use\n",
      "\n",
      "# <codecell>\n",
      "\n",
      "'''\n",
      "Load training and testing data\n",
      "'''\n",
      "def load_Training_Data(data_dir='./data/',files_to_use='all'):\n",
      "    files_to_use = files_To_Use(files_to_use)\n",
      "    train_sub_str = '_latlon_subset_19940101_20071231.nc'\n",
      "\n",
      "    print 'Loading training data...'\n",
      "    trainT, trainX, infos = load_GEFS_data(data_dir+'train/',files_to_use,train_sub_str)\n",
      "    trainY = load_csv_data(os.path.join(data_dir,'train.csv'))\n",
      "    print 'Training data shape',trainX.shape,trainY.shape\n",
      "    \n",
      "    # Load expected solar values for given days\n",
      "    solarData = np.loadtxt(\"../../Data/TSiteSolars.csv\",delimiter=',',dtype=float,skiprows=1)\n",
      "    augmentX = solarData[:,1:]\n",
      "    \n",
      "    return trainT, trainX, trainY, infos, augmentX\n",
      "\n",
      "'''\n",
      "Load testing data\n",
      "'''\n",
      "def load_Testing_Data(data_dir='./data/',files_to_use='all'):\n",
      "    files_to_use = files_To_Use(files_to_use)\n",
      "    test_sub_str = '_latlon_subset_20080101_20121130.nc'\n",
      "\n",
      "    print 'Loading test data...'\n",
      "    testT, testX, infos = load_GEFS_data(data_dir+'test/',files_to_use,test_sub_str)\n",
      "    print 'Test data shape',testX.shape\n",
      "   \n",
      "    # Load expected solar values for given days\n",
      "    solarData = np.loadtxt(\"../../Data/TSiteSolarsTest.csv\",delimiter=',',dtype=float,skiprows=1)\n",
      "    augmentX = solarData[:,1:]\n",
      "    \n",
      "    return testT, testX, infos, augmentX\n",
      "\n",
      "'''\n",
      "Load station info\n",
      "'''\n",
      "def load_Station_Info(data_dir='./data/'):\n",
      "\n",
      "    print 'Loading station info...'\n",
      "    infos = []\n",
      "    df = pd.read_csv(os.path.join(data_dir,'station_info.csv')).T\n",
      "    for i, station in df.iteritems():\n",
      "        temp = {'stid': station['stid'],\n",
      "                'lat': station['nlat'],\n",
      "                'lon': station['elon'],\n",
      "                'elev': station['elev'],\n",
      "                'index':i}\n",
      "        infos.append(temp)\n",
      "    return infos\n",
      "\n",
      "'''\n",
      "Get Times from data\n",
      "'''\n",
      "def load_Times(data_dir='./data/',file_to_use='dswrf_sfc',set='Train'):\n",
      "    if(set=='Train'):\n",
      "        sub_str = '_latlon_subset_20080101_20121130.nc'\n",
      "    elif(set=='Test'):\n",
      "        sub_str = '_latlon_subset_19940101_20071231.nc'\n",
      "\n",
      "    print 'Loading test data...'\n",
      "    data = load_GEFS_Object(data_dir+'test/',file_to_use,sub_str)\n",
      "    return data.variables['intTime'][:]\n",
      "\n",
      "'''\n",
      "Fit the Model with training data\n",
      "'''\n",
      "def fit_Model(trainX, trainY, model, N):\n",
      "    \n",
      "    print 'Finding best regularization value for alpha...'\n",
      "    alphas = np.logspace(-3,1,8,base=10) # List of alphas to check\n",
      "    #alphas = np.array(( 0.1, 0.2, 0.3, 0.4, 0.5, 0.6 ))\n",
      "    maes = []\n",
      "    for alpha in alphas:\n",
      "            model.alpha = alpha\n",
      "            mae = cv_loop(trainX,trainY,model,N)\n",
      "            maes.append(mae)\n",
      "            print 'alpha %.4f mae %.4f' % (alpha,mae)\n",
      "    best_alpha = alphas[np.argmin(maes)]\n",
      "    print 'Best alpha of %s with mean average error of %s' % (best_alpha,np.min(maes))\n",
      "    \n",
      "    print 'Fitting model with best alpha...'\n",
      "    model.alpha = best_alpha\n",
      "    model.fit(trainX,trainY)\n",
      "    \n",
      "    return times, trainX, trainY\n",
      "\n",
      "'''\n",
      "Test the Model with testing data\n",
      "'''\n",
      "def test_Model(testX, model):\n",
      "    \n",
      "    print 'Predicting...'\n",
      "    preds = model.predict(testX)\n",
      "    \n",
      "    return preds\n",
      "\n",
      "def pcaStuff(inputX,inputY):\n",
      "    pca = PCA(copy=True, n_components=50, whiten=False)\n",
      "    pca.fit(inputX,inputY)\n",
      "    outputX = pca.transform(inputX)\n",
      "    return pca, outputX\n",
      "\n",
      "def getSolarRadiation(lat, lon, time):\n",
      "    altitude = ps.GetAltitude(lat, lon, time)\n",
      "    return ps.radiation.GetRadiationDirect(time, altitude)\n",
      "\n",
      "def getDailySolar(lat, lon, day):\n",
      "    dailySolar = 0\n",
      "    for minute in range(0, 24*60, 5):\n",
      "        time = day + datetime.timedelta(minutes=minute)\n",
      "        dailySolar += getSolarRadiation(lat, lon, time)\n",
      "    dailySolar *= 300 #3600(joules per watt)*(5.0/60.0)(sample time)\n",
      "    return dailySolar\n",
      "\n",
      "def getMaxSolar(lat, lon, times):\n",
      "    maxSolarEnergy = []\n",
      "    for day in times:\n",
      "        day = datetime.datetime.strptime(str(day),'%Y%m%d')\n",
      "        maxSolarEnergy.append(getDailySolar(lat, lon, day))\n",
      "    return maxSolarEnergy\n",
      "\n",
      "def genSiteSolar(data_dir='./data/', saveFileName='SiteSolars.csv'):\n",
      "    with open(os.path.join(data_dir,saveFileName), 'wb') as csvfile:\n",
      "        spamwriter = csv.writer(csvfile)    \n",
      "        times,trainY = load_csv_data(os.path.join(data_dir,'test.csv'))\n",
      "        df = pd.read_csv(os.path.join(data_dir,'station_info.csv')).T\n",
      "        dates = ['Date'] + list(times)\n",
      "        spamwriter.writerow(dates)\n",
      "        for i, station in df.iteritems():\n",
      "            maxSolar = getMaxSolar(station['nlat'], station['elon'], times)\n",
      "            stid = [station['stid']] + maxSolar\n",
      "            spamwriter.writerow(stid)\n",
      "            print('Job: ', i, ' Station: ', station['stid'])\n",
      "    \n",
      "    a = izip(*csv.reader(open(os.path.join(data_dir,saveFileName), \"rb\")))\n",
      "    csv.writer(open(os.path.join(data_dir,'T'+saveFileName), \"wb\")).writerows(a)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Loads a list of GEFS files merging them into model format.\n",
      "'''\n",
      "def load_GEFS_data(directory,files_to_use,file_sub_str):\n",
      "    for i,f in enumerate(files_to_use):\n",
      "        if i == 0:\n",
      "            T, X, infos = load_GEFS_file(directory,files_to_use[i],file_sub_str)\n",
      "            X = np.expand_dims(X, axis=1)\n",
      "        else:\n",
      "            T, X_new, infos = load_GEFS_file(directory,files_to_use[i],file_sub_str)\n",
      "            X_new = np.expand_dims(X_new, axis=1)\n",
      "            X = np.hstack((X,X_new))\n",
      "    X = X.reshape(X.shape[0],X.shape[1],X.shape[2],X.shape[3],X.shape[4]*X.shape[5])\n",
      "    X = np.swapaxes(X,1,4)\n",
      "    return T, X, infos\n",
      "\n",
      "'''\n",
      "Loads GEFS file using specified merge technique.\n",
      "'''\n",
      "def load_GEFS_file(directory,data_type,file_sub_str):\n",
      "    print 'loading',data_type\n",
      "    path = os.path.join(directory,data_type+file_sub_str)\n",
      "    print 'this is the path: ', path\n",
      "    data = nc.Dataset(path,'r+')\n",
      "    T = data.variables['intTime'][:]\n",
      "    X = data.variables.values()[-1][:,:,:,:,:] # get rid of some GEFS points\n",
      "    infos = []\n",
      "    lats = data.variables['lat'][:]\n",
      "    lons = data.variables['lon'][:]-360\n",
      "    for lat in lats:\n",
      "        for lon in lons:\n",
      "            info = {'lat':lat,'lon':lon}\n",
      "            infos.append(info)\n",
      "    #X = X.reshape(X.shape[0],55,4,10)                               # Reshape to merge sub_models and time_forcasts\n",
      "    #X = np.mean(X,axis=1)                                            # Average models, but not hours\n",
      "    #X = X.reshape(X.shape[0],np.prod(X.shape[1:]))                   # Reshape into (n_examples,n_features)\n",
      "    return T, X, infos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainT, trainX, trainY, GEFS_infos, augmentX =load_Training_Data(data_dir,files_to_use)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading training data...\n",
        "loading dswrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/dswrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " dlwrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/dlwrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " uswrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/uswrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ulwrf_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/ulwrf_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " ulwrf_tatm\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/ulwrf_tatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pwat_eatm\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/pwat_eatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tcdc_eatm\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tcdc_eatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " apcp_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/apcp_sfc_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " pres_msl\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/pres_msl_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " spfh_2m\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/spfh_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tcolc_eatm\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tcolc_eatm_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmax_2m\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tmax_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmin_2m\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tmin_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmp_2m\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tmp_2m_latlon_subset_19940101_20071231.nc\n",
        "loading"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " tmp_sfc\n",
        "this is the path:  /home/rox/Code/CS6601P2/Data/train/tmp_sfc_latlon_subset_19940101_20071231.nc\n",
        "Training data shape"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (5113, 144, 11, 5, 15) (5113, 98)\n"
       ]
      }
     ],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Training data shape',trainX.shape,trainY.shape\n",
      "trainX.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training data shape (5113, 144, 11, 5, 15) (5113, 98)\n"
       ]
      },
      {
       "output_type": "pyout",
       "prompt_number": 97,
       "text": [
        "(5113, 144, 11, 5, 15)"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "station_infos = load_Station_Info(data_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading station info...\n"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class station:\n",
      "\n",
      "    def __init__(self, info, model, config):\n",
      "        '''Create a Station Model'''\n",
      "        # Store the info about the station\n",
      "        self.info   = info\n",
      "        \n",
      "        # Store the regression model used\n",
      "        # for each weather prediction model\n",
      "        self.models = [model]*11\n",
      "        \n",
      "        # Store the configuration of the station\n",
      "        self.config = config\n",
      "        \n",
      "        # Store the GEFS points to be used\n",
      "        self.GEFSs  = self.getGEFSs()\n",
      "    \n",
      "    def fit(self, X_train, y_train):\n",
      "        '''Fit the Station Model'''\n",
      "        X_train = self.filterGEFSX(X_train)\n",
      "        y_train = self.filterGEFSy(y_train)\n",
      "        for i,model in enumerate(self.models):\n",
      "            print \"Fitting Model:\", i\n",
      "            X = X_train[:,:,i]\n",
      "            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n",
      "            model.fit(X,y_train)\n",
      "         \n",
      "    def predict(self, X_test, wModels=None):\n",
      "        '''Predict with the Station Model'''\n",
      "        X_test = self.filterGEFSX(X_test)\n",
      "        if (wModels == None):\n",
      "            wModels = range(11)\n",
      "        for i,index in enumerate(wModels):\n",
      "            print \"Predicting Model:\", index\n",
      "            X = X_test[:,:,index]\n",
      "            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n",
      "            model = self.models[index]\n",
      "            if i == 0:\n",
      "                prediction = model.predict(X)\n",
      "            else:\n",
      "                prediction = np.vstack((prediction,model.predict(X)))\n",
      "        return prediction\n",
      "    \n",
      "    def getDistance(self,station, GEFS):\n",
      "        '''Find the distance from the Station'''\n",
      "        lat1, lon1 = [station['lat'], station['lon']]\n",
      "        lat2, lon2 = [GEFS['lat'], GEFS['lon']]\n",
      "        radius = 6371 # km\n",
      "    \n",
      "        dlat = math.radians(lat2-lat1)\n",
      "        dlon = math.radians(lon2-lon1)\n",
      "        a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
      "            * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
      "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
      "        d = radius * c\n",
      "    \n",
      "        return d\n",
      "    \n",
      "    def getGEFSs(self):\n",
      "        '''Get only the GEFS that are the N closest for config'''\n",
      "        distances = []\n",
      "        for index, GEFS in enumerate(self.info['GEFSs']):\n",
      "            distance = self.getDistance(self.info['station'], GEFS)\n",
      "            distances.append([index,distance])\n",
      "        distances = sorted(distances,key=lambda l:l[1])\n",
      "        GEFSs = []\n",
      "        N = self.config['nGEFS']\n",
      "        for index, GEFS in distances[0:N]:\n",
      "            GEFSs.append(index)\n",
      "        return GEFSs\n",
      "    \n",
      "    def filterGEFSX(self, X):\n",
      "        '''Filter X data to just used GEFS points'''\n",
      "        for i, GEFS in enumerate(self.GEFSs):\n",
      "            if i == 0:\n",
      "                X_new = X[:,GEFS]\n",
      "                X_new = np.expand_dims(X_new, axis=1)\n",
      "            else:\n",
      "                X_temp = X[:,GEFS]\n",
      "                X_temp = np.expand_dims(X_temp, axis=1)\n",
      "                X_new = np.hstack((X_new,X_temp))\n",
      "        return X_new\n",
      "    \n",
      "    def filterGEFSy(self, y):\n",
      "        '''Filter y data to just used GEFS points'''\n",
      "        y_new = y[:,self.info['station']['index']]\n",
      "        return y_new\n",
      "            \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n",
      "          'learning_rate': 0.01, 'loss': 'ls'}\n",
      "model = ensemble.GradientBoostingRegressor()\n",
      "config = {'nGEFS':4}\n",
      "\n",
      "stations = []\n",
      "for station_info in station_infos:\n",
      "    info = {'station':station_info,\n",
      "            'GEFSs':GEFS_infos}\n",
      "    temp_station = station(info, model, config)\n",
      "    stations.append(temp_station)\n",
      "\n",
      "    '''\n",
      "for station in stations:\n",
      "    station.fit(X_train, y_train)\n",
      "    \n",
      "for station in stations:\n",
      "    prediction = station.predict(X_test)'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lol = stations[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lul = lol.filterGEFSX(trainX)\n",
      "lul.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 102,
       "text": [
        "(5113, 4, 11, 5, 15)"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainX.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 103,
       "text": [
        "(5113, 144, 11, 5, 15)"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lul = lol.filterGEFSy(trainY)\n",
      "lul.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 104,
       "text": [
        "(5113,)"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainY[:,0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 105,
       "text": [
        "(5113,)"
       ]
      }
     ],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if np.array_equal(trainY[:,0],lul):\n",
      "    print 'Yha!'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Yha!\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lol.fit(trainX,trainY)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting Model: 0\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 5\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 9\n",
        "Fitting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lul = lol.predict(trainX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Predicting Model: 0\n",
        "Predicting Model: 1\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2\n",
        "Predicting Model: 3\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4\n",
        "Predicting Model: 5\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 6\n",
        "Predicting Model: 7\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 8\n",
        "Predicting Model: 9\n",
        "Predicting Model:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 10\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lul.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 109,
       "text": [
        "(11, 5113)"
       ]
      }
     ],
     "prompt_number": 109
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(lul[0])\n",
      "plt.plot(trainY[:,0])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for model in range(11):\n",
      "    print metrics.mean_absolute_error(trainY[:,0],lul[model])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1973072.56643\n",
        "2026948.01557\n",
        "2046730.91203\n",
        "2026715.81727\n",
        "2031394.58314\n",
        "2053483.96274\n",
        "2048165.70586\n",
        "2043626.40918\n",
        "2052730.29723\n",
        "2067643.69772\n",
        "1837909.21342\n"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n=0\n",
      "m=5115\n",
      "for model in range(11):\n",
      "    print metrics.mean_absolute_error(trainY[:,0][m*n:m*(n+1)],lul[model][m*n:m*(n+1)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1973072.56643\n",
        "2026948.01557\n",
        "2046730.91203\n",
        "2026715.81727\n",
        "2031394.58314\n",
        "2053483.96274\n",
        "2048165.70586\n",
        "2043626.40918\n",
        "2052730.29723\n",
        "2067643.69772\n",
        "1837909.21342\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bob = np.mean(lul,0)\n",
      "bob.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 112,
       "text": [
        "(5113,)"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.mean_absolute_error(trainY[:,0],bob)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1942926.13627\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainX.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "(5113, 144, 11, 5, 15)"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lol.GEFSs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "[72, 56, 71, 73]"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    }
   ],
   "metadata": {}
  }
 ]
}