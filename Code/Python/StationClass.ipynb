{
 "metadata": {
  "name": "StationClass"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from SolarDefs import *\n",
      "from timeit import timeit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_dir = \"/home/rox/Code/CS6601P2/Data/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from SolarDirectories import data_dir # = '/media/Data/Project Data/Solar Energy/' \n",
      "# Set to your data directory assumes all data is in there - no nesting\n",
      "files_to_use = 'all' # Choices for files_to_use: the string all, or a list of strings corresponding to the unique part of a GEFS filename\n",
      "submit_name = 'submission_mod_whours.csv'\n",
      "args = { 'files_to_use': files_to_use, 'submit_name': submit_name}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainT, trainX, trainY, GEFS_infos, augmentX =load_Training_Data(data_dir,files_to_use)\n",
      "print 'trainT', trainT.shape\n",
      "print 'trainX', trainX.shape\n",
      "print 'trainY', trainY.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainDays = dayOfYear(trainT)\n",
      "trainDays = np.expand_dims(trainDays,1)\n",
      "trainCompDays = compexDayOfYear(trainT)\n",
      "trainMonths = monthOfYear(trainT)\n",
      "trainMonths = np.expand_dims(trainMonths,1)\n",
      "trainCompMonths = compexMonthOfYear(trainT)\n",
      "print 'trainDays', trainDays.shape\n",
      "print 'trainCompDays', trainCompDays.shape\n",
      "print 'trainMonths', trainMonths.shape\n",
      "print 'trainCompMonths', trainCompMonths.shape\n",
      "mod_train = np.hstack((trainDays,trainCompDays,trainMonths,trainCompMonths))\n",
      "print 'mod_train', mod_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "testT, testX, GEFS_infos, augmentTestX = load_Testing_Data(data_dir,files_to_use)\n",
      "print 'testT', testT.shape\n",
      "print 'testX', testX.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testDays = dayOfYear(testT)\n",
      "testDays = np.expand_dims(testDays,1)\n",
      "testCompDays = compexDayOfYear(testT)\n",
      "testMonths = monthOfYear(testT)\n",
      "testMonths = np.expand_dims(testMonths,1)\n",
      "testCompMonths = compexMonthOfYear(testT)\n",
      "print 'testDays', testDays.shape\n",
      "print 'testCompDays', testCompDays.shape\n",
      "print 'testMonths', testMonths.shape\n",
      "print 'testCompMonths', testCompMonths.shape\n",
      "mod_test = np.hstack((testDays,testCompDays,testMonths,testCompMonths))\n",
      "print 'mod_test', mod_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "station_infos = load_Station_Info(data_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class stationClass:\n",
      "\n",
      "    def __init__(self, info, model, config):\n",
      "        '''Create a Station Model'''\n",
      "        # Store the info about the station\n",
      "        self.info   = info\n",
      "        \n",
      "        # Store the regression model used\n",
      "        # for each weather prediction model\n",
      "        self.models = [model]*11\n",
      "        \n",
      "        # Store the configuration of the station\n",
      "        self.config = config\n",
      "        \n",
      "        # Store the GEFS points to be used\n",
      "        self.GEFSs  = self.getGEFSs()\n",
      "        \n",
      "    \n",
      "    def fit(self, X_train, y_train, wModels=None, mod_train=None):\n",
      "        '''Fit the Station Model'''\n",
      "        X_train = self.filterGEFSX(X_train)\n",
      "        y_train = self.filterGEFSy(y_train)\n",
      "        if (wModels == None):\n",
      "            wModels = range(11)\n",
      "        for i,index in enumerate(wModels):\n",
      "            print \"     Fitting Model:\", i\n",
      "            model = self.models[index]\n",
      "            X = X_train[:,:,i]\n",
      "            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n",
      "            if mod_train != None:\n",
      "                X = np.hstack((X,mod_train))\n",
      "            model.fit(X,y_train)\n",
      "         \n",
      "    def predict(self, X_test, wModels=None, mod_train=None):\n",
      "        '''Predict with the Station Model'''\n",
      "        X_test = self.filterGEFSX(X_test)\n",
      "        if (wModels == None):\n",
      "            wModels = range(11)\n",
      "        for i,index in enumerate(wModels):\n",
      "            print \"     Predicting Model:\", index\n",
      "            X = X_test[:,:,index]\n",
      "            X = X.reshape(X.shape[0],np.prod(X.shape[1:]))\n",
      "            if mod_train != None:\n",
      "                X = np.hstack((X,mod_train))\n",
      "            model = self.models[index]\n",
      "            if i == 0:\n",
      "                prediction = model.predict(X)\n",
      "            else:\n",
      "                prediction = np.vstack((prediction,model.predict(X)))\n",
      "        return prediction\n",
      "    \n",
      "    def getDistance(self,station, GEFS):\n",
      "        '''Find the distance from the Station'''\n",
      "        lat1, lon1 = [station['lat'], station['lon']]\n",
      "        lat2, lon2 = [GEFS['lat'], GEFS['lon']]\n",
      "        radius = 6371 # km\n",
      "    \n",
      "        dlat = math.radians(lat2-lat1)\n",
      "        dlon = math.radians(lon2-lon1)\n",
      "        a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
      "            * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
      "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
      "        d = radius * c\n",
      "    \n",
      "        return d\n",
      "    \n",
      "    def getGEFSs(self):\n",
      "        '''Get only the GEFS that are the N closest for config'''\n",
      "        distances = []\n",
      "        for index, GEFS in enumerate(self.info['GEFSs']):\n",
      "            distance = self.getDistance(self.info['station'], GEFS)\n",
      "            distances.append([index,distance])\n",
      "        distances = sorted(distances,key=lambda l:l[1])\n",
      "        GEFSs = []\n",
      "        N = self.config['nGEFS']\n",
      "        for index, GEFS in distances[0:N]:\n",
      "            GEFSs.append(index)\n",
      "        return GEFSs\n",
      "    \n",
      "    def filterGEFSX(self, X):\n",
      "        '''Filter X data to just used GEFS points'''\n",
      "        for i, GEFS in enumerate(self.GEFSs):\n",
      "            if i == 0:\n",
      "                X_new = X[:,GEFS]\n",
      "                X_new = np.expand_dims(X_new, axis=1)\n",
      "            else:\n",
      "                X_temp = X[:,GEFS]\n",
      "                X_temp = np.expand_dims(X_temp, axis=1)\n",
      "                X_new = np.hstack((X_new,X_temp))\n",
      "        return X_new\n",
      "    \n",
      "    def filterGEFSy(self, y):\n",
      "        '''Filter y data to just used GEFS points'''\n",
      "        y_new = y[:,self.info['station']['index']]\n",
      "        return y_new\n",
      "            \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def makeStations(station_infos, model, config):\n",
      "    stations = []\n",
      "    for station_info in station_infos:\n",
      "        info = {'station':station_info,\n",
      "                'GEFSs':GEFS_infos}\n",
      "        temp_station = stationClass(info, model, config)\n",
      "        stations.append(temp_station)\n",
      "    return stations\n",
      "    \n",
      "def fitStations(stations, X_train, y_train, wModels=None, mod_train=None):\n",
      "    for i, station in enumerate(stations):\n",
      "        print \"Fitting Station\", i\n",
      "        station.fit(X_train, y_train, wModels, mod_train)\n",
      "    return stations\n",
      "    \n",
      "def predictStations(stations, X_test, wModels=None, mod_train=None):\n",
      "    for i, station in enumerate(stations):\n",
      "        print \"Predict Station\", i\n",
      "        prediction = station.predict(X_test,wModels,mod_train)\n",
      "        if i == 0:\n",
      "            prediction = np.expand_dims(prediction,0)\n",
      "            predictions = prediction\n",
      "        else:\n",
      "            prediction = np.expand_dims(prediction,0)\n",
      "            predictions = np.vstack((finalPrediction,prediction))\n",
      "    return predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def savePickle(data, data_dir, file_name):\n",
      "    pickle.dump(data, open(os.path.join(data_dir,file_name), \"wb\"))\n",
      "    \n",
      "def loadPickle(data_dir, file_name):\n",
      "    data = pickle.load(open(os.path.join(data_dir,file_name), \"rb\"))\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def saveModels(stations, data_dir, file_name):\n",
      "    stationModels = []\n",
      "    for station in stations:\n",
      "        stationModels.append(station.models)\n",
      "    savePickle(stationModels, data_dir, file_name)\n",
      "    \n",
      "def loadModels(stations, data_dir, file_name):\n",
      "    stationModels = loadPickle(data_dir, file_name)\n",
      "    for i, station in enumerate(stations):\n",
      "        station.models = stationModels[i]\n",
      "    return stations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 1,\n",
      "          'learning_rate': 0.01, 'loss': 'ls'}\n",
      "model = ensemble.GradientBoostingRegressor(params)\n",
      "config = {'nGEFS':4}\n",
      "\n",
      "stations = makeStations(station_infos, model, config)\n",
      "\n",
      "#stations = fitStations(stations, trainX, trainY, None, mod_train)\n",
      "#saveModels(stations, data_dir, 'stationModels.p')\n",
      "stations = loadModels(stations, data_dir, 'stationModels.p')\n",
      "\n",
      "#predictions = predictStations(stations, testX, wModels=None, mod_train=None):\n",
      "#savePickle(predictions, data_dir, 'predictions.p')  \n",
      "predictions = loadPickle(data_dir, 'predictions.p')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def move_operator(weights):\n",
      "    weight_list = []\n",
      "    for i in range(len(weights)):\n",
      "        for j in range(i+1,len(weights)):\n",
      "            temp1 = list(weights)\n",
      "            temp1[i] += 0.01\n",
      "            temp1[j] -= 0.01\n",
      "            weight_list.append(temp1)\n",
      "            temp2 = list(weights)\n",
      "            temp2[i] -= 0.01\n",
      "            temp2[j] += 0.01\n",
      "            weight_list.append(temp2)\n",
      "    #print weight_list\n",
      "    return weight_list\n",
      "\n",
      "def score(truth, predicted, weights):\n",
      "    \n",
      "    prediction = np.array(predicted)\n",
      "    for i,j in enumerate(weights):\n",
      "        prediction[i] *= j\n",
      "        \n",
      "    final_prediction = np.sum(prediction,axis=0)\n",
      "    return metrics.mean_absolute_error(truth,final_prediction)\n",
      "\n",
      "def random_init(length):\n",
      "    weights = np.random.randint(10, size=length)\n",
      "    sum = np.sum(weights)\n",
      "    if sum == 0:\n",
      "        weights = np.array([1.0/length]*length)\n",
      "        sum = np.sum(weights)\n",
      "    weights = [temp/(sum*1.0) for temp in weights]\n",
      "    print 'random: ', weights\n",
      "    return weights\n",
      "\n",
      "def hillclimb(truth, prediction, max_evaluations):\n",
      "\n",
      "    best = random_init(prediction.shape[0])\n",
      "    best_score = score(truth, prediction, best)\n",
      "    first_score = best_score\n",
      "    \n",
      "    num_evaluations=1\n",
      "    \n",
      "    while num_evaluations < max_evaluations:\n",
      "        # examine moves around our current position\n",
      "        move_made=False\n",
      "        for nextW in move_operator(best):\n",
      "            if num_evaluations >= max_evaluations:\n",
      "                break\n",
      "            \n",
      "            # see if this move is better than the current\n",
      "            next_score = score(truth, prediction, nextW)\n",
      "            num_evaluations+=1\n",
      "            if next_score < best_score:\n",
      "                best=nextW\n",
      "                best_score=next_score\n",
      "                move_made=True\n",
      "                break # depth first search\n",
      "            \n",
      "        if not move_made:\n",
      "            break # we couldn't find a better move \n",
      "                     # (must be at a local maximum)\n",
      "    \n",
      "    return (num_evaluations,best_score,best,first_score)\n",
      "\n",
      "def hillclimb_reset(weights, truth, prediction, max_evaluations):\n",
      "\n",
      "    best = weights\n",
      "    best_score = score(truth, prediction, best)\n",
      "    \n",
      "    num_evaluations=0\n",
      "    \n",
      "    while num_evaluations < max_evaluations:\n",
      "        remaining_evaluations=max_evaluations-num_evaluations\n",
      "        \n",
      "        evaluated,score,found=hillclimb(weights, truth, prediction, max_evaluations)\n",
      "        \n",
      "        num_evaluations+=evaluated\n",
      "        if score > best_score or best is None:\n",
      "            best_score=score\n",
      "            best=found\n",
      "    \n",
      "    return (num_evaluations,best_score,best)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getWeights(station, X, y, mod_train=None, predictions=None):\n",
      "    #predictions = station.predict(X,wModels=None, mod_train=trainMonths)\n",
      "    stationTruth = station.filterGEFSy(y)\n",
      "    monthIndexs = []\n",
      "    for month in range(1,13):\n",
      "        monthIndexs.append(np.argwhere(trainMonths==month)[:,0])\n",
      "    monthWeights = []\n",
      "    for month in monthIndexs:\n",
      "        monthPredictions = predictions[:,month]\n",
      "        monthTruth = stationTruth[month]\n",
      "        num_evaluations,best_score,best,first_score = hillclimb(monthTruth, monthPredictions, 11000)\n",
      "        monthWeights.append(best)\n",
      "    return monthWeights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_evaluations,best_score,best,first_score = hillclimb(trainY[:,0], finalPrediction, 11000)\n",
      "\n",
      "\n",
      "#num_evaluations,best_score,best = (1,2,3)\n",
      "print best\n",
      "print first_score\n",
      "print best_score\n",
      "print num_evaluations\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getWeightPredicted(station, X, y, mod_train=None, predictions=None):\n",
      "    \n",
      "    for day in range(len(predictions):\n",
      "        \n",
      "    return monthWeights"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "monthWeights = getWeights(stations_mod[15], trainX, trainY,mod_train,finalPrediction[15])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "totalWeightList = []\n",
      "for i in range(98):\n",
      "    print 'i: ', i\n",
      "    monthWeights = getWeights(stations_mod[i], trainX, trainY,mod_train,finalPrediction[i])\n",
      "    totalWeightList.append(monthWeights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(totalWeightList[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(finalPrediction[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(98):\n",
      "    print 'i: ', i\n",
      "    monthWeights = getWeights(stations_mod[i], trainX, trainY,mod_train,finalPrediction[i])\n",
      "    totalWeightList.append(monthWeights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}